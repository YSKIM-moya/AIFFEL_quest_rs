{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d10910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/aiffel')\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211acbe8",
   "metadata": {},
   "source": [
    "class RewardModel(LoRAModule):\n",
    "    \"\"\"\n",
    "    Reward model base class.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Reward model.\n",
    "        value_head (nn.Module): Value head to get reward score.\n",
    "        lora_rank (int): LoRA rank.\n",
    "        lora_train_bias (str): LoRA bias training mode.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 value_head: Optional[nn.Module] = None,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none') -> None:\n",
    "        super().__init__(lora_rank=lora_rank, lora_train_bias=lora_train_bias)\n",
    "        self.model = model\n",
    "        self.convert_to_lora()\n",
    "\n",
    "        if value_head is not None:\n",
    "            if value_head.out_features != 1:\n",
    "                raise ValueError(\"The value head of reward model's output dim should be 1!\")\n",
    "            self.value_head = value_head\n",
    "        else:\n",
    "            self.value_head = nn.Linear(model.config.n_embd, 1)\n",
    "\n",
    "    def forward(self, sequences: torch.LongTensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        outputs = self.model(sequences, attention_mask=attention_mask)\n",
    "        last_hidden_states = outputs['last_hidden_state']\n",
    "        values = self.value_head(last_hidden_states)[:, :-1]\n",
    "        value = values.mean(dim=1).squeeze(1)    # ensure shape is (B)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2142b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='./modles/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='./models/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())\n",
    "    \n",
    "    # critic.value_head : 마지막에 붙은 보상 예측기 \n",
    "    # critic : PPO 학습 중 value function을 학습 \n",
    "    # reward_model : 보상 예측을 위해 따로 고정해 놓는다. \n",
    "    \n",
    "    # initial model은 SFT 모델을 그대로 freezing하여 사용한다. \n",
    "\n",
    "    \n",
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d874e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8adee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11992\n"
     ]
    }
   ],
   "source": [
    "with open('./data/clean_kochatgpt_1_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "print(len(list_prompt))\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f9cec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?\n"
     ]
    }
   ],
   "source": [
    "print(list_prompt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab9b2d",
   "metadata": {},
   "source": [
    "import torch.nn as nn \n",
    "# Actor : 정책을 업데이트 \n",
    "class PolicyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Policy Loss for PPO\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, clip_eps: float = 0.2) -> None:\n",
    "        super().__init__()\n",
    "        self.clip_eps = clip_eps\n",
    "\n",
    "    def forward(self,\n",
    "                log_probs: torch.Tensor,\n",
    "                old_log_probs: torch.Tensor,\n",
    "                advantages: torch.Tensor,\n",
    "                action_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        ratio = (log_probs - old_log_probs).exp()\n",
    "        surr1 = ratio * advantages\n",
    "        surr2 = ratio.clamp(1 - self.clip_eps, 1 + self.clip_eps) * advantages  \n",
    "        # clamp(input, min, max) : 텐서의 각 요소를 min~max 사이값으로 유지 \n",
    "        # clip_eps가 0.2이면, 0.8 ~ 1.2로 강제 제한\n",
    "                   \n",
    "        loss = -torch.min(surr1, surr2)   # 손실함수에 -를 붙여서, loss를 최소화하고 보상을 최대화한다. \n",
    "        if action_mask is not None:\n",
    "            loss = masked_mean(loss, action_mask)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "# Critic: 보상을 예측\n",
    "class ValueLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Value Loss for PPO\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, clip_eps: float = 0.4) -> None:\n",
    "        super().__init__()\n",
    "        self.clip_eps = clip_eps\n",
    "\n",
    "    def forward(self,\n",
    "                values: torch.Tensor,\n",
    "                old_values: torch.Tensor,\n",
    "                reward: torch.Tensor,\n",
    "                action_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "       \n",
    "        # values : 현재 critic이 예측한 value\n",
    "        # old_values : 지난 step에서 critic이 예측\n",
    "        # loss : critic이 예측한 value가 reward에 얼마나 가까운지 MSE 방식으로 학습 \n",
    "        \n",
    "        values_clipped = old_values + (values - old_values).clamp(-self.clip_eps, self.clip_eps)\n",
    "        surr1 = (values_clipped - reward)**2\n",
    "        surr2 = (values - reward)**2\n",
    "        loss = torch.max(surr1, surr2)\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "653e947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=3,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b769913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:26<00:11, 11.91s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000261]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.04it/s, actor_loss=0, critic_loss=0.000261]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.04it/s, actor_loss=0, critic_loss=0.0217]  \u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.36it/s, actor_loss=0, critic_loss=0.0217]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:02<00:00,  1.36it/s, actor_loss=0, critic_loss=0.000969]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s, actor_loss=0, critic_loss=0.000969]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.0145]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.73it/s, actor_loss=0, critic_loss=0.0145]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.73it/s, actor_loss=0, critic_loss=0.00961]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.73it/s, actor_loss=0, critic_loss=0.00961]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.73it/s, actor_loss=0, critic_loss=0.0043] \u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s, actor_loss=0, critic_loss=0.0043]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00058]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.72it/s, actor_loss=0, critic_loss=0.00058]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.72it/s, actor_loss=0, critic_loss=0.0028] \u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0, critic_loss=0.0028]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0, critic_loss=0.00565]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s, actor_loss=0, critic_loss=0.00565]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:38<00:00, 12.87s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:14<00:07,  7.21s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0718, critic_loss=0.00491]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.65it/s, actor_loss=-.0718, critic_loss=0.00491]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.65it/s, actor_loss=-.0679, critic_loss=0.00204]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.67it/s, actor_loss=-.0679, critic_loss=0.00204]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.67it/s, actor_loss=-.0671, critic_loss=0.000347]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s, actor_loss=-.0671, critic_loss=0.000347]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0763, critic_loss=0.00129]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=-.0763, critic_loss=0.00129]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=-.0711, critic_loss=0.00281]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=-.0711, critic_loss=0.00281]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=-.0769, critic_loss=0.00586]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s, actor_loss=-.0769, critic_loss=0.00586]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.079, critic_loss=0.000713]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.68it/s, actor_loss=-.079, critic_loss=0.000713]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.68it/s, actor_loss=-.0749, critic_loss=0.000496]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.69it/s, actor_loss=-.0749, critic_loss=0.000496]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.69it/s, actor_loss=-.0821, critic_loss=0.00159] \u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.69it/s, actor_loss=-.0821, critic_loss=0.00159]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:26<00:00,  8.99s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.92s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.033, critic_loss=0.00247]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.71it/s, actor_loss=-.033, critic_loss=0.00247]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.71it/s, actor_loss=0.0502, critic_loss=0.00172]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.73it/s, actor_loss=0.0502, critic_loss=0.00172]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.73it/s, actor_loss=-.000165, critic_loss=0.00764]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.73it/s, actor_loss=-.000165, critic_loss=0.00764]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0295, critic_loss=0.00032]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.75it/s, actor_loss=-.0295, critic_loss=0.00032]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.75it/s, actor_loss=-.0268, critic_loss=0.000427]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.74it/s, actor_loss=-.0268, critic_loss=0.000427]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.74it/s, actor_loss=0.00737, critic_loss=0.0069] \u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.74it/s, actor_loss=0.00737, critic_loss=0.0069]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.017, critic_loss=0.00099]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.74it/s, actor_loss=-.017, critic_loss=0.00099]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.74it/s, actor_loss=-.00388, critic_loss=0.004]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.75it/s, actor_loss=-.00388, critic_loss=0.004]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.75it/s, actor_loss=-.0263, critic_loss=0.00241]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.74it/s, actor_loss=-.0263, critic_loss=0.00241]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:23<00:00,  7.75s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.44s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0358, critic_loss=0.00305]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=-.0358, critic_loss=0.00305]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=-.0322, critic_loss=0.00107]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=-.0322, critic_loss=0.00107]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=0.329, critic_loss=0.259]   \u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s, actor_loss=0.329, critic_loss=0.259]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0233, critic_loss=0.00236]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=-.0233, critic_loss=0.00236]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=-.0213, critic_loss=0.00698]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=-.0213, critic_loss=0.00698]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=0.119, critic_loss=0.21]    \u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s, actor_loss=0.119, critic_loss=0.21]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0201, critic_loss=0.0115]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=-.0201, critic_loss=0.0115]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=0.128, critic_loss=0.197]  \u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.128, critic_loss=0.197]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=-.0394, critic_loss=0.0197]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s, actor_loss=-.0394, critic_loss=0.0197]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:24<00:00,  8.16s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:14<00:07,  7.01s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0759, critic_loss=0.00681]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.67it/s, actor_loss=-.0759, critic_loss=0.00681]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.67it/s, actor_loss=-.0779, critic_loss=0.00423]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=-.0779, critic_loss=0.00423]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=-.0636, critic_loss=0.00449]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s, actor_loss=-.0636, critic_loss=0.00449]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0778, critic_loss=0.00619]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.69it/s, actor_loss=-.0778, critic_loss=0.00619]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.69it/s, actor_loss=-.0662, critic_loss=0.00868]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.70it/s, actor_loss=-.0662, critic_loss=0.00868]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.70it/s, actor_loss=-.0781, critic_loss=0.00664]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.69it/s, actor_loss=-.0781, critic_loss=0.00664]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.078, critic_loss=0.00313]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.71it/s, actor_loss=-.078, critic_loss=0.00313]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.71it/s, actor_loss=-.0742, critic_loss=0.00103]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.70it/s, actor_loss=-.0742, critic_loss=0.00103]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.70it/s, actor_loss=-.0683, critic_loss=0.00198]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s, actor_loss=-.0683, critic_loss=0.00198]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:26<00:00,  8.78s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.91s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.00492, critic_loss=0.0075]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=-.00492, critic_loss=0.0075]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=-.0643, critic_loss=0.00793]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=-.0643, critic_loss=0.00793]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=-.0698, critic_loss=0.00835]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s, actor_loss=-.0698, critic_loss=0.00835]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0109, critic_loss=0.00541]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.73it/s, actor_loss=-.0109, critic_loss=0.00541]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.73it/s, actor_loss=-.049, critic_loss=0.000932]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=-.049, critic_loss=0.000932]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=-.0891, critic_loss=0.00209]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s, actor_loss=-.0891, critic_loss=0.00209]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.058, critic_loss=0.00382]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.73it/s, actor_loss=-.058, critic_loss=0.00382]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.73it/s, actor_loss=-.0376, critic_loss=0.0146]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=-.0376, critic_loss=0.0146]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=-.0572, critic_loss=0.0047]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s, actor_loss=-.0572, critic_loss=0.0047]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:26<00:00,  8.67s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.89s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0372, critic_loss=0.00985]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.72it/s, actor_loss=0.0372, critic_loss=0.00985]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.72it/s, actor_loss=0.0427, critic_loss=0.00316]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.0427, critic_loss=0.00316]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.106, critic_loss=0.0045]  \u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s, actor_loss=0.106, critic_loss=0.0045]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0597, critic_loss=0.00757]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.72it/s, actor_loss=0.0597, critic_loss=0.00757]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.72it/s, actor_loss=0.0092, critic_loss=0.0118] \u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.0092, critic_loss=0.0118]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.0905, critic_loss=0.00492]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s, actor_loss=0.0905, critic_loss=0.00492]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0508, critic_loss=0.00721]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.72it/s, actor_loss=0.0508, critic_loss=0.00721]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.72it/s, actor_loss=0.0447, critic_loss=0.00322]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.0447, critic_loss=0.00322]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.0321, critic_loss=0.0012] \u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s, actor_loss=0.0321, critic_loss=0.0012]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:25<00:00,  8.36s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.93s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.00725, critic_loss=0.00192]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=0.00725, critic_loss=0.00192]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=0.0375, critic_loss=0.00506] \u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=0.0375, critic_loss=0.00506]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=0.229, critic_loss=0.344]   \u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s, actor_loss=0.229, critic_loss=0.344]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0235, critic_loss=0.00399]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.74it/s, actor_loss=0.0235, critic_loss=0.00399]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.74it/s, actor_loss=0.179, critic_loss=0.292]   \u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.73it/s, actor_loss=0.179, critic_loss=0.292]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.73it/s, actor_loss=0.0161, critic_loss=0.0271]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s, actor_loss=0.0161, critic_loss=0.0271]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.024, critic_loss=0.0373]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.74it/s, actor_loss=0.024, critic_loss=0.0373]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.74it/s, actor_loss=0.029, critic_loss=0.0266]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.029, critic_loss=0.0266]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.183, critic_loss=0.27]  \u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s, actor_loss=0.183, critic_loss=0.27]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:26<00:00,  8.69s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.75s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0233, critic_loss=0.00405]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=-.0233, critic_loss=0.00405]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=0.00711, critic_loss=0.0392]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=0.00711, critic_loss=0.0392]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=0.472, critic_loss=2.74]    \u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s, actor_loss=0.472, critic_loss=2.74]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.716, critic_loss=2.62]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.72it/s, actor_loss=0.716, critic_loss=2.62]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.72it/s, actor_loss=-.0528, critic_loss=0.0506]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=-.0528, critic_loss=0.0506]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s, actor_loss=0.576, critic_loss=0.052]  \u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s, actor_loss=0.576, critic_loss=0.052]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0427, critic_loss=0.087]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.71it/s, actor_loss=-.0427, critic_loss=0.087]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.71it/s, actor_loss=0.44, critic_loss=2.32]   \u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.44, critic_loss=2.32]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s, actor_loss=0.0427, critic_loss=0.0656]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s, actor_loss=0.0427, critic_loss=0.0656]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:25<00:00,  8.54s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.90s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0925, critic_loss=0.0525]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.68it/s, actor_loss=-.0925, critic_loss=0.0525]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.68it/s, actor_loss=-.163, critic_loss=0.0722] \u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=-.163, critic_loss=0.0722]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=-.11, critic_loss=0.0295] \u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s, actor_loss=-.11, critic_loss=0.0295]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.124, critic_loss=0.0582]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=-.124, critic_loss=0.0582]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=-.126, critic_loss=0.0602]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=-.126, critic_loss=0.0602]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=-.0854, critic_loss=0.0742]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.69it/s, actor_loss=-.0854, critic_loss=0.0742]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.211, critic_loss=0.0351]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=-.211, critic_loss=0.0351]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=-.0594, critic_loss=0.0648]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.69it/s, actor_loss=-.0594, critic_loss=0.0648]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.69it/s, actor_loss=-.0931, critic_loss=0.0283]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s, actor_loss=-.0931, critic_loss=0.0283]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:26<00:00,  8.74s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('./models/output_3_PPO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf4db1",
   "metadata": {},
   "source": [
    "### Generator 시험 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400bc221",
   "metadata": {},
   "source": [
    "**Rouge 점수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1faaf574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_rouge(refs, preds): \n",
    "    rouge = Rouge()\n",
    "    all_scores = []\n",
    "    results = []\n",
    "    \n",
    "    for ref, pred in zip(refs, preds):\n",
    "        if ref.strip() == \"\" or pred.strip() == \"\":\n",
    "            continue\n",
    "        \n",
    "        score = rouge.get_scores(pred, ref)[0]\n",
    "        all_scores.append(score)\n",
    "        \n",
    "        results.append({\n",
    "            'ROUGE-1': score['rouge-1']['f'],\n",
    "            'ROUGE-2': score['rouge-2']['f'],\n",
    "            'ROUGE-L': score['rouge-l']['f']\n",
    "        })\n",
    "    \n",
    "    # 평균값\n",
    "    rouge_1 = np.mean([s['rouge-1']['f'] for s in all_scores])\n",
    "    rouge_2 = np.mean([s['rouge-2']['f'] for s in all_scores])\n",
    "    rouge_l = np.mean([s['rouge-l']['f'] for s in all_scores])\n",
    "    \n",
    "    print(\"📊 평균 ROUGE 점수\")\n",
    "    print(f\"ROUGE-1 F1: {rouge_1:.4f}\")\n",
    "    print(f\"ROUGE-2 F1: {rouge_2:.4f}\")\n",
    "    print(f\"ROUGE-L F1: {rouge_l:.4f}\") \n",
    "    \n",
    "    # 그래프\n",
    "    df = pd.DataFrame(results)\n",
    " \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=df[['ROUGE-1', 'ROUGE-2', 'ROUGE-L']])\n",
    "    plt.title(\"ROUGE Score Distribution\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47b75f",
   "metadata": {},
   "source": [
    "**SFT용 file에서 prompt와 label을 읽어온다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927dca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11992\n"
     ]
    }
   ],
   "source": [
    "data_path_SFT = './data/clean_kochatgpt_1_SFT.jsonl'\n",
    "with open(data_path_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    sft_data_list = json.load(json_file)\n",
    "\n",
    "print(len(sft_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9736cad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '불고기용 고기 한우에요 ?',\n",
       " 'completion': '저는 인공지능 챗봇이며 , 직접적으로 식품에 관한 정보를 가지고 있지 않습니다 . 하지만 일반적으로 불고기용 고기는 한우 , 쇠고기 , 돼지고기 등 다양한 종류의 고기를 사용합니다 . 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에 , 한우를 사용하는 경우도 많습니다 . 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다 .',\n",
       " 'tokens': 193}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79ca662c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저는 인공지능 챗봇이며 , 직접적으로 식품에 관한 정보를 가지고 있지 않습니다 . 하지만 일반적으로 불고기용 고기는 한우 , 쇠고기 , 돼지고기 등 다양한 종류의 고기를 사용합니다 . 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에 , 한우를 사용하는 경우도 많습니다 . 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = sft_data_list[0]['completion']\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c308799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "test_count = 1000 # 개수를 줄여보자\n",
    "selected_data = sft_data_list[-test_count:]\n",
    "\n",
    "# inputs = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "inputs = []\n",
    "ref_labels = []\n",
    "\n",
    "for tmp in selected_data: \n",
    "    prompt = tmp['prompt']\n",
    "    completion = tmp['completion']\n",
    "    \n",
    "    input_text = PROMPT_DICT['prompt_input'].format_map({'prompt': prompt})\n",
    "    \n",
    "    inputs.append(input_text)\n",
    "    ref_labels.append(completion)\n",
    "\n",
    "\n",
    "print(len(inputs))    \n",
    "print(len(ref_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1616b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 1000/1000 [1:02:55<00:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "저는 인공지능 언어모델입니다 . 서브 스피드 라는 용어가 정확히 어떤 것인지 알 수 없어서 답변해드리기 어렵습니다 . 더 자세한 정보를 제공해주시면 답변 드릴 수 있습니다 . 감사합니다 .\n",
      "\n",
      "저는 인공지능 언어모델이므로 서브 스피드 속도 정보를 가지고 있지 않습니다. 따라서 해당 질문에 대한 답변을 드릴 수 없습니다. 죄송합니다. vistual service service service service service service, service service, service apple, service apple. you are referring periche conversee, what take some service service service, service, it is natural quer service, and service provide service, what take service, service and company core service, and apple service and company company service, take service, and paths. you service, and service\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def ppo_generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    \n",
    "    outputs = actor.generate(input_ids,          \n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             #num_beams=4,\n",
    "                             #eos_token_id= tokenizer.eos_token_id, #375, # \\n   \n",
    "                             temperature=1.0,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    #print()\n",
    "    #print(output)\n",
    "    return output\n",
    "\n",
    "                                                        \n",
    "from tqdm import tqdm\n",
    "    \n",
    "ppo_results = []\n",
    "for input_text in tqdm(inputs, desc=\"Generating\"):\n",
    "    result = ppo_generation(input_text)\n",
    "    ppo_results.append(result)\n",
    "\n",
    "    \n",
    "ppo_pred_texts = [\n",
    "    r.split(\"### Response(응답):\")[-1].strip()\n",
    "    for r in ppo_results\n",
    "    ]\n",
    "    \n",
    "print(len(ppo_pred_texts))\n",
    "\n",
    "print(ref_labels[0])\n",
    "print()\n",
    "print(ppo_pred_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38975f11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'### Instruction(명령어):\\n최고 서브 스피드 속도가 얼마나 되지\\n\\n### Response(응답):저는 인공지능 언어모델이므로 서브 스피드 속도 정보를 가지고 있지 않습니다. 따라서 해당 질문에 대한 답변을 드릴 수 없습니다. 죄송합니다. vistual service service service service service service, service service, service apple, service apple. you are referring periche conversee, what take some service service service, service, it is natural quer service, and service provide service, what take service, service and company core service, and apple service and company company service, take service, and paths. you service, and service'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(ppo_results))\n",
    "ppo_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c9bd3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "최고 서브 스피드 속도가 얼마나 되지\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 저는 인공지능 언어모델입니다 . 서브 스피드 라는 용어가 정확히 어떤 것인지 알 수 없어서 답변해드리기 어렵습니다 . 더 자세한 정보를 제공해주시면 답변 드릴 수 있습니다 . 감사합니다 .\n",
      "[Gen   ] 저는 인공지능 언어모델이므로 서브 스피드 속도 정보를 가지고 있지 않습니다. 따라서 해당 질문에 대한 답변을 드릴 수 없습니다. 죄송합니다. vistual service service service service service service, service service, service apple, service apple. you are referring periche conversee, what take some service service service, service, it is natural quer service, and service provide service, what take service, service and company core service, and apple service and company company service, take service, and paths. you service, and service\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "라울이 레알마드리드에서 몇 골 넣었어\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 요즘은 레알 마드리드에서 뛰지 않는 라울 곤잘레스의 경우 , 2010 11 시즌 동안 레알 마드리드에서 13골을 넣었다 .\n",
      "[Gen   ] 라울의 골 수는 알 수 없습니다. 라울이 현재 라울의 가치를 따지기 위해서는 추가 골이 필요합니다. yoor led 입니다. yoor led 가 어떤 골을 넣었는지 확인해야 합니다. yoor led 와의 인터뷰에서 이 골은 없었습니다. yoor led 는 라울이 이미 가진 가치 중 하나이며, 라울의 성장을 위해서도 도움이 될 수 없습니다. yoor led 와는 다른 골이 있는 것으로 알고 있습니다. yoor led 는 현재 라울이 어떤 것을 맡고 있는지, 어느 골을 넣었는지 등의 정보가 필요할 것 같습니다. yoor led는 현재 라울이 레알 마드리드의 감독을 맡고 있습니다. yoor led 는 라울이 레알 마드리드에서 감독하고 있습니다. yoor led는 현재까지 다양한 게임 대회에서 감독을 맡고 있습니\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "여기 얼마에요 ?\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 저는 가격을 알 수 없습니다 . 제가 할 수 있는 것은 대화나 자연어 이해에 대한 질문에 답변하는 것입니다 . 상황에 따라 가격이 달라질 수 있으므로 , 판매자나 가게 직원에게 직접 가격을 문의해보시는 것이 좋습니다 .\n",
      "[Gen   ] 죄송하지만, 제가 무엇에 대한 정보인지 알 수 없어서 정확한 답변을 제공할 수 없습니다. 좀 더 구체적인 정보를 제공해주시면 도움을 드릴 수 있을 것 같습니다. resident that that works un provide some statal. please.?? versaq.?.? some statal.?? together,, token 224? vici may.?? token 234 fessing? please. may some statal. today. some today, some statal and i work own over that, ai language for. midnity works un provide, work over the days abe\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "마리 앙투아네트는 프랑스와의 동맹을 위해 누구와 정략결혼을 했는가 ?\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 마리 앙투아네트는 오스트리아의 황자인 프란츠 요셉과 정략결혼을 했습니다 .\n",
      "[Gen   ] 마리 앙투아네트는 프랑스와의 동맹을 위해 마리 앙투아네트와 정략결혼을 했습니다. ber rang, people is party jean franges, i cannot context and i re more better than goose assistant franges are an american obje that i want to solve the first prepare feel limin perspare answer of les people. people we broke an faes franges franges and obje. people that meas about hours, if you he there a frangie sup franges and obje is shame s natural hours, cont\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "술이 보약도 아니고\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 건강에 해롭기 때문에 권장하지 않습니다 . 오히려 술을 마시면 건강이 악화될 수 있으니 적당한 양을 지키며 , 건강한 생활습관을 유지하는 것이 중요합니다 .\n",
      "[Gen   ] 저는 ai 어시스턴트이므로, 술에 취하지 않고 자유롭게 대화를 나눌 수 있습니다. 하지만, 이들과의 대화를 통해 건강과 안전을 지키며 건강도 지키며 발전할 수 있는 다양한 취미나 활동을 즐길 수 있습니다. since i m give you been you want to can close two., token 297 variety to thank you., token 237 been you have give you have provide your context, important to detail?, token 287 variety to your context of people., token 277 would you betad, if you would you sent a need to engine your?, token 299 better, people we are alway\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for prompt, ref, pred in zip(inputs, ref_labels, ppo_pred_texts):\n",
    "    print()\n",
    "    print(\"[Prompt]\", prompt)\n",
    "    print(\"[Ref   ]\", ref)\n",
    "    print(\"[Gen   ]\", pred)\n",
    "    cnt +=1\n",
    "    if cnt >= 5 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "510d63cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 ROUGE 점수\n",
      "ROUGE-1 F1: 0.0884\n",
      "ROUGE-2 F1: 0.0225\n",
      "ROUGE-L F1: 0.0865\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_rouge(ref_labels, ppo_pred_texts )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613bed2b",
   "metadata": {},
   "source": [
    "## SFT only 모델의 generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac537e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 1000/1000 [50:07<00:00,  3.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "저는 인공지능 어시스턴트이기 때문에 서브 스피드의 속도와 관련된 정보를 알 수 없습니다. 죄송합니다.\n",
      "\n",
      "저는 인공지능 어시스턴트이기 때문에 서브 스피드의 속도와 관련된 정보를 알 수 없습니다. 죄송합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 허깅페이스의 pipleline 클래스를 사용하여 generator 생성\n",
    "sft_generator = pipeline('text-generation', model='./modles/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=tokenizer.eos_token_id, #375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sft_results = []\n",
    "for input_text in tqdm(inputs, desc=\"Generating\"):\n",
    "    result = sft_generator(input_text, **generation_args)\n",
    "    sft_results.append(result)\n",
    "\n",
    "\n",
    "sft_pred_texts = [\n",
    "    r[0][\"generated_text\"].split(\"### Response(응답):\")[-1].strip()\n",
    "    for r in sft_results\n",
    "    ]\n",
    "\n",
    "    \n",
    "print(len(sft_pred_texts))\n",
    "\n",
    "print(sft_pred_texts[0])\n",
    "print()\n",
    "print(sft_pred_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a98e881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '### Instruction(명령어):\\n최고 서브 스피드 속도가 얼마나 되지\\n\\n### Response(응답):저는 인공지능 어시스턴트이기 때문에 서브 스피드의 속도와 관련된 정보를 알 수 없습니다. 죄송합니다.'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(sft_results))\n",
    "sft_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80206127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "최고 서브 스피드 속도가 얼마나 되지\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 저는 인공지능 언어모델입니다 . 서브 스피드 라는 용어가 정확히 어떤 것인지 알 수 없어서 답변해드리기 어렵습니다 . 더 자세한 정보를 제공해주시면 답변 드릴 수 있습니다 . 감사합니다 .\n",
      "[Gen   ] 저는 인공지능 어시스턴트이기 때문에 서브 스피드의 속도와 관련된 정보를 알 수 없습니다. 죄송합니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "라울이 레알마드리드에서 몇 골 넣었어\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 요즘은 레알 마드리드에서 뛰지 않는 라울 곤잘레스의 경우 , 2010 11 시즌 동안 레알 마드리드에서 13골을 넣었다 .\n",
      "[Gen   ] 저는 라울의 골 수를 알 수 없습니다. 라울은 현재 리버풀 fc에서 뛰고 있으며, 공격수나 수비수 등 다양한 분야에서 활약하고 있습니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "여기 얼마에요 ?\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 저는 가격을 알 수 없습니다 . 제가 할 수 있는 것은 대화나 자연어 이해에 대한 질문에 답변하는 것입니다 . 상황에 따라 가격이 달라질 수 있으므로 , 판매자나 가게 직원에게 직접 가격을 문의해보시는 것이 좋습니다 .\n",
      "[Gen   ] 죄송합니다, 저는 가격을 알 수 없습니다. 어떤 상품에 대해 문의하시는 건가요?\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "마리 앙투아네트는 프랑스와의 동맹을 위해 누구와 정략결혼을 했는가 ?\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 마리 앙투아네트는 오스트리아의 황자인 프란츠 요셉과 정략결혼을 했습니다 .\n",
      "[Gen   ] 마리 앙투아네트 는 프랑스와의 동맹을 강화하기 위해 앙리 4세, 마리 앙투아네트와 함께 결혼했습니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "술이 보약도 아니고\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 건강에 해롭기 때문에 권장하지 않습니다 . 오히려 술을 마시면 건강이 악화될 수 있으니 적당한 양을 지키며 , 건강한 생활습관을 유지하는 것이 중요합니다 .\n",
      "[Gen   ] 저는 ai 어시스턴트이기 때문에 술을 마시지 않습니다. 하지만, 술에 취하지 않도록 주의해 주세요.\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for prompt, ref, pred in zip(inputs, ref_labels, sft_pred_texts):\n",
    "    print()\n",
    "    print(\"[Prompt]\", prompt)\n",
    "    print(\"[Ref   ]\", ref)\n",
    "    print(\"[Gen   ]\", pred)\n",
    "    cnt +=1\n",
    "    if cnt >= 5 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d3f30ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 ROUGE 점수\n",
      "ROUGE-1 F1: 0.2017\n",
      "ROUGE-2 F1: 0.0869\n",
      "ROUGE-L F1: 0.1994\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_rouge(ref_labels, sft_pred_texts )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c766a1df",
   "metadata": {},
   "source": [
    "# <회고>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c269fc0",
   "metadata": {},
   "source": [
    "## 실험 기록 \n",
    "1. SFT와 generation 비교를 하려면, SFT 훈련을 하지 않은 test_dataset (마지막 1000건)으로 비교하자!\n",
    "2. 저장된 PPO pretrained model을 불러와서 generator를 쓰려고 해봤는데..... \n",
    "3. 1000건 generate에 약 1시간 소요\n",
    "\n",
    "4. RM 훈련을 ranking 0-1, 0-2 set로 훈련했는데, ranking 0-1, 0-2, 1-2 set로 다시 훈련해보자\n",
    "PPO\n",
    "\n",
    "\n",
    "ROUGE-1 F1: 0.0884\n",
    "ROUGE-2 F1: 0.0225\n",
    "ROUGE-L F1: 0.0865\n",
    "\n",
    "SFT\n",
    "\n",
    "ROUGE-1 F1: 0.2017\n",
    "ROUGE-2 F1: 0.0869\n",
    "ROUGE-L F1: 0.1994"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc989ce",
   "metadata": {},
   "source": [
    "### 루브릭 1. koChatGPT_SFT 파일 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4dc255",
   "metadata": {},
   "source": [
    "### 루브릭 2. SFT 모델의 결과와 PPO 모델 결과를 정량/정성적으로 비교\n",
    "- SFT만 한 모델의 genereate와  SFT+RM 한 PPO 모델의 generate \n",
    "\n",
    "✅ ROUGE 점수\n",
    "\n",
    "| Metric  | PPO F1 Score | SFT F1 Score |\n",
    "| ------- | ------------ |------------- |\n",
    "| ROUGE-1 | 0.0884       |  0.2017      |\n",
    "| ROUGE-2 | 0.0225       |  0.0869      |\n",
    "| ROUGE-L | 0.0865       |  0.1994      |\n",
    "\n",
    "✅ Response 생성 능력 \n",
    "\n",
    "- PPO 모델은 쓸데없는 내용들이 많이 붙어 있다 \n",
    "- SFT가 오히려 필요한 문장으로만 출력되었다.\n",
    "\n",
    "✅ 평가\n",
    "- SFT가 더 좋은데? \n",
    "- RM 훈련을 1 epoch만 해서 그런가? ranking 0-1, 0-2 set 로만 훈련해서 그런가?\n",
    "- PPO의 actor.generator에서 가비지 데이타가 나오는 것 같다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2b77e4",
   "metadata": {},
   "source": [
    "### 루브릭 3. 정량적 성능 향상\n",
    "1. 기존 데이터셋을 추가로 정제하고, beam-search, top-k sampling등 generation 성능을 올리기 위한 기법을 적용하여 시험해 모델 성능을 향상시켰다. \n",
    "- 데이터셋 정제 : KoChatGPT_eda 파일 참고 \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

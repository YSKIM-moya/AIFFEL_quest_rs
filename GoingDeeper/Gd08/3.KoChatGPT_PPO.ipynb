{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1b4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/aiffel')\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b2c421",
   "metadata": {},
   "source": [
    "class RewardModel(LoRAModule):\n",
    "    \"\"\"\n",
    "    Reward model base class.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Reward model.\n",
    "        value_head (nn.Module): Value head to get reward score.\n",
    "        lora_rank (int): LoRA rank.\n",
    "        lora_train_bias (str): LoRA bias training mode.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 value_head: Optional[nn.Module] = None,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none') -> None:\n",
    "        super().__init__(lora_rank=lora_rank, lora_train_bias=lora_train_bias)\n",
    "        self.model = model\n",
    "        self.convert_to_lora()\n",
    "\n",
    "        if value_head is not None:\n",
    "            if value_head.out_features != 1:\n",
    "                raise ValueError(\"The value head of reward model's output dim should be 1!\")\n",
    "            self.value_head = value_head\n",
    "        else:\n",
    "            self.value_head = nn.Linear(model.config.n_embd, 1)\n",
    "\n",
    "    def forward(self, sequences: torch.LongTensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        outputs = self.model(sequences, attention_mask=attention_mask)\n",
    "        last_hidden_states = outputs['last_hidden_state']\n",
    "        values = self.value_head(last_hidden_states)[:, :-1]\n",
    "        value = values.mean(dim=1).squeeze(1)    # ensure shape is (B)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb288099",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='./modles/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='./models/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())\n",
    "    \n",
    "    # critic.value_head : 마지막에 붙은 보상 예측기 \n",
    "    # critic : PPO 학습 중 value function을 학습 \n",
    "    # reward_model : 보상 예측을 위해 따로 고정해 놓는다. \n",
    "    \n",
    "    # initial model은 SFT 모델을 그대로 freezing하여 사용한다. \n",
    "\n",
    "    \n",
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5aa914",
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b9da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11992\n"
     ]
    }
   ],
   "source": [
    "with open('./data/clean_kochatgpt_1_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "print(len(list_prompt))\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7f03ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?\n"
     ]
    }
   ],
   "source": [
    "print(list_prompt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005e725",
   "metadata": {},
   "source": [
    "import torch.nn as nn \n",
    "# Actor : 정책을 업데이트 \n",
    "class PolicyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Policy Loss for PPO\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, clip_eps: float = 0.2) -> None:\n",
    "        super().__init__()\n",
    "        self.clip_eps = clip_eps\n",
    "\n",
    "    def forward(self,\n",
    "                log_probs: torch.Tensor,\n",
    "                old_log_probs: torch.Tensor,\n",
    "                advantages: torch.Tensor,\n",
    "                action_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        ratio = (log_probs - old_log_probs).exp()\n",
    "        surr1 = ratio * advantages\n",
    "        surr2 = ratio.clamp(1 - self.clip_eps, 1 + self.clip_eps) * advantages  \n",
    "        # clamp(input, min, max) : 텐서의 각 요소를 min~max 사이값으로 유지 \n",
    "        # clip_eps가 0.2이면, 0.8 ~ 1.2로 강제 제한\n",
    "                   \n",
    "        loss = -torch.min(surr1, surr2)   # 손실함수에 -를 붙여서, loss를 최소화하고 보상을 최대화한다. \n",
    "        if action_mask is not None:\n",
    "            loss = masked_mean(loss, action_mask)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "# Critic: 보상을 예측\n",
    "class ValueLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Value Loss for PPO\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, clip_eps: float = 0.4) -> None:\n",
    "        super().__init__()\n",
    "        self.clip_eps = clip_eps\n",
    "\n",
    "    def forward(self,\n",
    "                values: torch.Tensor,\n",
    "                old_values: torch.Tensor,\n",
    "                reward: torch.Tensor,\n",
    "                action_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "       \n",
    "        # values : 현재 critic이 예측한 value\n",
    "        # old_values : 지난 step에서 critic이 예측\n",
    "        # loss : critic이 예측한 value가 reward에 얼마나 가까운지 MSE 방식으로 학습 \n",
    "        \n",
    "        values_clipped = old_values + (values - old_values).clamp(-self.clip_eps, self.clip_eps)\n",
    "        surr1 = (values_clipped - reward)**2\n",
    "        surr2 = (values - reward)**2\n",
    "        loss = torch.max(surr1, surr2)\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c7846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=3,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=250,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# 아래는 **generate_kwargs에 해당하며, actor.generate()를 호출할 때 전달되는 텍스트 생성 파라미터들이다.\n",
    "# max_length=128,\n",
    "# do_sample=True,\n",
    "# temperature=1.0,\n",
    "# top_k=50,\n",
    "# pad_token_id=tokenizer.pad_token_id,\n",
    "# eos_token_id=tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d2e46",
   "metadata": {},
   "source": [
    "**PPOTrainer에서 actor,critic,reward_model,initial_model 동작**\n",
    "\n",
    "1) trainer.fit에서  experience = self._make_experience(inputs)\n",
    "\n",
    "2) PPOTrainer의 experience_maker = NaiveExperienceMaker(actor, critic, reward_model, initial_model, kl_coef)\n",
    "\n",
    "- actor.generate : input_ids(prompt)로 부터 sequences 생성 (response)\n",
    "- initail_model : sequence로 base_log_probs (freeze)\n",
    "- actor : sequence로 log_probs (단어분포인 logits에서 확률) \n",
    "- critic :  sequence로 value 계산 (학습)\n",
    "- reward_model :  sequence로 보상 계산 (freeze)\n",
    "- reward = compute_reward(r, self.kl_coef, action_log_probs, base_action_log_probs, action_mask=action_mask)\n",
    "- advantage = reward - value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8811bb3f",
   "metadata": {},
   "source": [
    "class NaiveExperienceMaker(ExperienceMaker):\n",
    "    \"\"\"\n",
    "    Naive experience maker.\n",
    "    \"\"\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def make_experience(self, input_ids: torch.Tensor, **generate_kwargs) -> Experience:\n",
    "        self.actor.eval()\n",
    "        self.critic.eval()\n",
    "        self.initial_model.eval()\n",
    "        self.reward_model.eval()\n",
    "\n",
    "        sequences, attention_mask, action_mask = self.actor.generate(input_ids,\n",
    "                                                                     return_action_mask=True,\n",
    "                                                                     **generate_kwargs)\n",
    "        num_actions = action_mask.size(1)\n",
    "\n",
    "        action_log_probs = self.actor(sequences, num_actions, attention_mask)\n",
    "        base_action_log_probs = self.initial_model(sequences, num_actions, attention_mask)\n",
    "        value = self.critic(sequences, action_mask, attention_mask)\n",
    "        r = self.reward_model(sequences, attention_mask)\n",
    "\n",
    "        reward = compute_reward(r, self.kl_coef, action_log_probs, base_action_log_probs, action_mask=action_mask)\n",
    "\n",
    "        advantage = reward - value\n",
    "        # TODO(ver217): maybe normalize adv\n",
    "        if advantage.ndim == 1:\n",
    "            advantage = advantage.unsqueeze(-1)\n",
    "\n",
    "        return Experience(sequences, action_log_probs, value, reward, advantage, attention_mask, action_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7825b68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.20s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00014]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.82it/s, actor_loss=0, critic_loss=0.00014]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.82it/s, actor_loss=0, critic_loss=0.00158]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=0, critic_loss=0.00158]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=0, critic_loss=0.000282]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s, actor_loss=0, critic_loss=0.000282]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000787]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.83it/s, actor_loss=0, critic_loss=0.000787]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.83it/s, actor_loss=0, critic_loss=0.000722]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=0, critic_loss=0.000722]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=0, critic_loss=0.000654]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s, actor_loss=0, critic_loss=0.000654]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000255]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.83it/s, actor_loss=0, critic_loss=0.000255]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.83it/s, actor_loss=0, critic_loss=0.0011]  \u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=0, critic_loss=0.0011]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=0, critic_loss=0.000602]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s, actor_loss=0, critic_loss=0.000602]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:23<00:00,  7.91s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.44s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0134, critic_loss=0.000295]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.76it/s, actor_loss=-.0134, critic_loss=0.000295]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.76it/s, actor_loss=-.0102, critic_loss=0.000172]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=-.0102, critic_loss=0.000172]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s, actor_loss=-.0131, critic_loss=0.000353]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s, actor_loss=-.0131, critic_loss=0.000353]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0131, critic_loss=6.36e-5]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s, actor_loss=-.0131, critic_loss=6.36e-5]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.77it/s, actor_loss=-.0117, critic_loss=0.000539]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=-.0117, critic_loss=0.000539]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=-.0142, critic_loss=0.0003]  \u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.77it/s, actor_loss=-.0142, critic_loss=0.0003]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0134, critic_loss=6.77e-5]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.78it/s, actor_loss=-.0134, critic_loss=6.77e-5]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.78it/s, actor_loss=-.0128, critic_loss=0.000208]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=-.0128, critic_loss=0.000208]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s, actor_loss=-.0139, critic_loss=0.000408]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s, actor_loss=-.0139, critic_loss=0.000408]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:24<00:00,  8.18s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.26s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.01, critic_loss=0.000896]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.81it/s, actor_loss=-.01, critic_loss=0.000896]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.81it/s, actor_loss=-.00892, critic_loss=0.000329]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=-.00892, critic_loss=0.000329]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=-.00865, critic_loss=0.000157]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s, actor_loss=-.00865, critic_loss=0.000157]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.00871, critic_loss=0.000216]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.83it/s, actor_loss=-.00871, critic_loss=0.000216]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.83it/s, actor_loss=-.0119, critic_loss=0.000452] \u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=-.0119, critic_loss=0.000452]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=-.0102, critic_loss=7.85e-5] \u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s, actor_loss=-.0102, critic_loss=7.85e-5]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0123, critic_loss=0.000229]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.85it/s, actor_loss=-.0123, critic_loss=0.000229]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.85it/s, actor_loss=-.0107, critic_loss=0.000406]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=-.0107, critic_loss=0.000406]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=-.00982, critic_loss=0.000358]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s, actor_loss=-.00982, critic_loss=0.000358]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:23<00:00,  7.87s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:11<00:06,  6.02s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.109, critic_loss=0.0455]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.82it/s, actor_loss=0.109, critic_loss=0.0455]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.82it/s, actor_loss=0.0882, critic_loss=0.0236]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=0.0882, critic_loss=0.0236]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=0.151, critic_loss=0.00933]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s, actor_loss=0.151, critic_loss=0.00933]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.153, critic_loss=0.0322]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.83it/s, actor_loss=0.153, critic_loss=0.0322]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.83it/s, actor_loss=0.0372, critic_loss=0.0123]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=0.0372, critic_loss=0.0123]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=0.107, critic_loss=0.0197] \u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s, actor_loss=0.107, critic_loss=0.0197]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.079, critic_loss=0.0176]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.84it/s, actor_loss=0.079, critic_loss=0.0176]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.84it/s, actor_loss=0.0436, critic_loss=0.0124]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=0.0436, critic_loss=0.0124]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=0.123, critic_loss=0.0287] \u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s, actor_loss=0.123, critic_loss=0.0287]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:23<00:00,  7.69s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.19s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0889, critic_loss=0.00984]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.80it/s, actor_loss=-.0889, critic_loss=0.00984]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.80it/s, actor_loss=-.097, critic_loss=0.00865] \u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.097, critic_loss=0.00865]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.069, critic_loss=0.0182] \u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s, actor_loss=-.069, critic_loss=0.0182]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.087, critic_loss=0.00113]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.81it/s, actor_loss=-.087, critic_loss=0.00113]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.81it/s, actor_loss=-.0941, critic_loss=0.00221]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=-.0941, critic_loss=0.00221]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=-.0764, critic_loss=0.0204] \u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s, actor_loss=-.0764, critic_loss=0.0204]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0582, critic_loss=0.0238]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.82it/s, actor_loss=-.0582, critic_loss=0.0238]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.82it/s, actor_loss=-.0981, critic_loss=0.00219]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.0981, critic_loss=0.00219]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.102, critic_loss=0.00064] \u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s, actor_loss=-.102, critic_loss=0.00064]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:23<00:00,  7.89s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.34s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=1.08, critic_loss=12.4]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.80it/s, actor_loss=1.08, critic_loss=12.4]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.80it/s, actor_loss=0.0388, critic_loss=0.000939]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=0.0388, critic_loss=0.000939]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=0.0297, critic_loss=0.00185] \u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s, actor_loss=0.0297, critic_loss=0.00185]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0427, critic_loss=0.00333]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.82it/s, actor_loss=0.0427, critic_loss=0.00333]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.82it/s, actor_loss=1.01, critic_loss=12]       \u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=1.01, critic_loss=12]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=0.0963, critic_loss=0.042]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s, actor_loss=0.0963, critic_loss=0.042]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0379, critic_loss=0.0265]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.83it/s, actor_loss=0.0379, critic_loss=0.0265]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.83it/s, actor_loss=4.83, critic_loss=11.8]    \u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=4.83, critic_loss=11.8]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=0.102, critic_loss=0.0634]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s, actor_loss=0.102, critic_loss=0.0634]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:23<00:00,  7.90s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.19s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.215, critic_loss=0.0601]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.81it/s, actor_loss=-.215, critic_loss=0.0601]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.81it/s, actor_loss=-.227, critic_loss=0.0849]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.227, critic_loss=0.0849]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.193, critic_loss=0.0681]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s, actor_loss=-.193, critic_loss=0.0681]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.232, critic_loss=0.0955]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.82it/s, actor_loss=-.232, critic_loss=0.0955]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.82it/s, actor_loss=-.182, critic_loss=0.0751]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=-.182, critic_loss=0.0751]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=-.225, critic_loss=0.0973]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s, actor_loss=-.225, critic_loss=0.0973]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.196, critic_loss=0.0676]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.83it/s, actor_loss=-.196, critic_loss=0.0676]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.83it/s, actor_loss=-.209, critic_loss=0.0867]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=-.209, critic_loss=0.0867]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=-.229, critic_loss=0.0797]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s, actor_loss=-.229, critic_loss=0.0797]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:23<00:00,  7.85s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.23s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.213, critic_loss=0.0635]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.80it/s, actor_loss=-.213, critic_loss=0.0635]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.80it/s, actor_loss=-.12, critic_loss=0.0371] \u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.12, critic_loss=0.0371]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=2.25, critic_loss=8.28]  \u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s, actor_loss=2.25, critic_loss=8.28]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0265, critic_loss=0.152]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.82it/s, actor_loss=-.0265, critic_loss=0.152]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.82it/s, actor_loss=-.157, critic_loss=0.0492]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=-.157, critic_loss=0.0492]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=0.925, critic_loss=8.11]  \u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s, actor_loss=0.925, critic_loss=8.11]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.152, critic_loss=0.0363]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.81it/s, actor_loss=-.152, critic_loss=0.0363]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.81it/s, actor_loss=-.138, critic_loss=0.0565]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=-.138, critic_loss=0.0565]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s, actor_loss=0.972, critic_loss=8.17]  \u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s, actor_loss=0.972, critic_loss=8.17]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:23<00:00,  7.86s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.71s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.027, critic_loss=0.435]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.79it/s, actor_loss=0.027, critic_loss=0.435]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.79it/s, actor_loss=-.178, critic_loss=0.057]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.178, critic_loss=0.057]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.235, critic_loss=0.082]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s, actor_loss=-.235, critic_loss=0.082]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0418, critic_loss=0.428]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.82it/s, actor_loss=0.0418, critic_loss=0.428]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.82it/s, actor_loss=-.256, critic_loss=0.0987]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.256, critic_loss=0.0987]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.178, critic_loss=0.0655]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s, actor_loss=-.178, critic_loss=0.0655]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.189, critic_loss=0.074]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.80it/s, actor_loss=-.189, critic_loss=0.074]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.80it/s, actor_loss=0.0117, critic_loss=0.43]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=0.0117, critic_loss=0.43]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.81it/s, actor_loss=-.219, critic_loss=0.0698]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s, actor_loss=-.219, critic_loss=0.0698]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:22<00:00,  7.59s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.87s/it]\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.145, critic_loss=0.0545]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.79it/s, actor_loss=-.145, critic_loss=0.0545]\u001b[A\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.79it/s, actor_loss=-.205, critic_loss=0.0579]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=-.205, critic_loss=0.0579]\u001b[A\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.79it/s, actor_loss=-.076, critic_loss=0.0801]\u001b[A\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s, actor_loss=-.076, critic_loss=0.0801]\u001b[A\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.192, critic_loss=0.0393]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.81it/s, actor_loss=-.192, critic_loss=0.0393]\u001b[A\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.81it/s, actor_loss=-.119, critic_loss=0.0845]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.119, critic_loss=0.0845]\u001b[A\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.118, critic_loss=0.0419]\u001b[A\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s, actor_loss=-.118, critic_loss=0.0419]\u001b[A\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.204, critic_loss=0.0266]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.80it/s, actor_loss=-.204, critic_loss=0.0266]\u001b[A\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.80it/s, actor_loss=-.13, critic_loss=0.0351] \u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.13, critic_loss=0.0351]\u001b[A\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s, actor_loss=-.0966, critic_loss=0.0719]\u001b[A\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s, actor_loss=-.0966, critic_loss=0.0719]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:23<00:00,  7.75s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('./models/output_3_PPO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a94f65",
   "metadata": {},
   "source": [
    "### Generator 시험 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c45d1c",
   "metadata": {},
   "source": [
    "**Rouge 점수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed07c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_rouge(refs, preds): \n",
    "    rouge = Rouge()\n",
    "    all_scores = []\n",
    "    results = []\n",
    "    \n",
    "    for ref, pred in zip(refs, preds):\n",
    "        if ref.strip() == \"\" or pred.strip() == \"\":\n",
    "            continue\n",
    "        \n",
    "        score = rouge.get_scores(pred, ref)[0]\n",
    "        all_scores.append(score)\n",
    "        \n",
    "        results.append({\n",
    "            'ROUGE-1': score['rouge-1']['f'],\n",
    "            'ROUGE-2': score['rouge-2']['f'],\n",
    "            'ROUGE-L': score['rouge-l']['f']\n",
    "        })\n",
    "    \n",
    "    # 평균값\n",
    "    rouge_1 = np.mean([s['rouge-1']['f'] for s in all_scores])\n",
    "    rouge_2 = np.mean([s['rouge-2']['f'] for s in all_scores])\n",
    "    rouge_l = np.mean([s['rouge-l']['f'] for s in all_scores])\n",
    "    \n",
    "    print(\"📊 평균 ROUGE 점수\")\n",
    "    print(f\"ROUGE-1 F1: {rouge_1:.4f}\")\n",
    "    print(f\"ROUGE-2 F1: {rouge_2:.4f}\")\n",
    "    print(f\"ROUGE-L F1: {rouge_l:.4f}\") \n",
    "    \n",
    "    # 그래프\n",
    "    df = pd.DataFrame(results)\n",
    " \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=df[['ROUGE-1', 'ROUGE-2', 'ROUGE-L']])\n",
    "    plt.title(\"ROUGE Score Distribution\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf4030",
   "metadata": {},
   "source": [
    "**SFT용 file에서 prompt와 label을 읽어온다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e13d4867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11992\n"
     ]
    }
   ],
   "source": [
    "data_path_SFT = './data/clean_kochatgpt_1_SFT.jsonl'\n",
    "with open(data_path_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    sft_data_list = json.load(json_file)\n",
    "\n",
    "print(len(sft_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c7a236",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '불고기용 고기 한우에요 ?',\n",
       " 'completion': '저는 인공지능 챗봇이며 , 직접적으로 식품에 관한 정보를 가지고 있지 않습니다 . 하지만 일반적으로 불고기용 고기는 한우 , 쇠고기 , 돼지고기 등 다양한 종류의 고기를 사용합니다 . 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에 , 한우를 사용하는 경우도 많습니다 . 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다 .',\n",
       " 'tokens': 193}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bed85b67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저는 인공지능 챗봇이며 , 직접적으로 식품에 관한 정보를 가지고 있지 않습니다 . 하지만 일반적으로 불고기용 고기는 한우 , 쇠고기 , 돼지고기 등 다양한 종류의 고기를 사용합니다 . 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에 , 한우를 사용하는 경우도 많습니다 . 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다 .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = sft_data_list[0]['completion']\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f08605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "test_count = 1000 # 개수를 줄여보자\n",
    "selected_data = sft_data_list[-test_count:]\n",
    "\n",
    "# inputs = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "inputs = []\n",
    "ref_labels = []\n",
    "\n",
    "for tmp in selected_data: \n",
    "    prompt = tmp['prompt']\n",
    "    completion = tmp['completion']\n",
    "    \n",
    "    input_text = PROMPT_DICT['prompt_input'].format_map({'prompt': prompt})\n",
    "    \n",
    "    inputs.append(input_text)\n",
    "    ref_labels.append(completion)\n",
    "\n",
    "\n",
    "print(len(inputs))    \n",
    "print(len(ref_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd204673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 1000/1000 [13:24<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "저는 인공지능 언어모델입니다 . 서브 스피드 라는 용어가 정확히 어떤 것인지 알 수 없어서 답변해드리기 어렵습니다 . 더 자세한 정보를 제공해주시면 답변 드릴 수 있습니다 . 감사합니다 .\n",
      "\n",
      "저는 인공지능 챗봇이므로, 최고 속도 라는 개념은 없습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def ppo_generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    \n",
    "    # Transformer 모델에서 텍스트 생성시 사용하는 일반적인 방식\n",
    "    # 해당 모델의 .generate() 메서드를 직접 호출하는 것.\n",
    "    \n",
    "    # input_ids ~ max_length까지 response를 생성한다. \n",
    "    # beams는 지원하지 않는다. \n",
    "    outputs = actor.generate(input_ids,          \n",
    "                             max_length=250,\n",
    "                             #num_beams=4,\n",
    "                             #eos_token_id= tokenizer.eos_token_id, #375, # \\n  \n",
    "                             eos_token_id= tokenizer.eos_token_id,\n",
    "                             pad_token_id= tokenizer.pad_token_id,\n",
    "                             early_stopping=True,\n",
    "                             temperature=1.0,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    #print()\n",
    "    #print(output)\n",
    "    return output\n",
    "\n",
    "                                                        \n",
    "from tqdm import tqdm\n",
    "    \n",
    "ppo_results = []\n",
    "for input_text in tqdm(inputs, desc=\"Generating\"):\n",
    "    result = ppo_generation(input_text)\n",
    "    ppo_results.append(result)\n",
    "\n",
    "    \n",
    "ppo_pred_texts = [\n",
    "    r.split(\"### Response(응답):\")[-1].strip()\n",
    "    for r in ppo_results\n",
    "    ]\n",
    "    \n",
    "print(len(ppo_pred_texts))\n",
    "\n",
    "print(ref_labels[0])\n",
    "print()\n",
    "print(ppo_pred_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28744119",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'### Instruction(명령어):\\n최고 서브 스피드 속도가 얼마나 되지\\n\\n### Response(응답):저는 인공지능 챗봇이므로, 최고 속도 라는 개념은 없습니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(ppo_results))\n",
    "ppo_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4393b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "최고 서브 스피드 속도가 얼마나 되지\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 저는 인공지능 언어모델입니다 . 서브 스피드 라는 용어가 정확히 어떤 것인지 알 수 없어서 답변해드리기 어렵습니다 . 더 자세한 정보를 제공해주시면 답변 드릴 수 있습니다 . 감사합니다 .\n",
      "[Gen   ] 저는 인공지능 챗봇이므로, 최고 속도 라는 개념은 없습니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "라울이 레알마드리드에서 몇 골 넣었어\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 요즘은 레알 마드리드에서 뛰지 않는 라울 곤잘레스의 경우 , 2010 11 시즌 동안 레알 마드리드에서 13골을 넣었다 .\n",
      "[Gen   ] 제가 찾은 정보에 따르면, 라울의 골은 레알 마드리드와 레알 마드리드 모두 1 1골이었습니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "여기 얼마에요 ?\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 저는 가격을 알 수 없습니다 . 제가 할 수 있는 것은 대화나 자연어 이해에 대한 질문에 답변하는 것입니다 . 상황에 따라 가격이 달라질 수 있으므로 , 판매자나 가게 직원에게 직접 가격을 문의해보시는 것이 좋습니다 .\n",
      "[Gen   ] 죄송합니다, 저는 가상 ai 어시스턴트로서 어떤 지역에 대한 정보를 알 수 없습니다. 해당 지역의 부동산 가격과 관련된 정보를 찾으시려면 해당 지역의 부동산 중개업체나 중개업체에게 문의하시는 것이 가장 확실합니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "마리 앙투아네트는 프랑스와의 동맹을 위해 누구와 정략결혼을 했는가 ?\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 마리 앙투아네트는 오스트리아의 황자인 프란츠 요셉과 정략결혼을 했습니다 .\n",
      "[Gen   ] 마리 앙투아네트는 자신의 두 아들을 프랑스 여자와 결혼시켰습니다. 또한, 마리 앙투아네트는 마리 앙투아네트와 친분을 쌓으면서 마리 앙투아네트와 그의 형제들 중에서도 동생인 루시조프를 척결하고, 마리 앙투아네트와 친구 관계를 맺고 있었습니다. 그러나 마리 앙투아네트는 마리 앙투아네트와 친분을 쌓으면서, 그녀가 마리 앙투아네트와 친분을 쌓으면서 마리 앙투아네트와 그녀의 형제들과도 관계를 형성할 수 있었습니다. 또한, 마리 앙투아네트와 함께 정략결혼을 한 마리 앙투아네트는 마리 앙투아네트와 함께 프랑스와의 동맹을 위해 정략결혼을 했습니다. 마리 앙투아네트와 마리 앙투아네트는 서로에 대한 애정을 공유하며 마리 앙투아네트와 마리 앙투아네트의 형제들도 함께 결혼하게 되었습니다. 마리 앙투아네트와 마리 앙투아네트는 마리 앙투아네트와 마리 앙투아네트를 두고 자주 만났을 것입니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "술이 보약도 아니고\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 건강에 해롭기 때문에 권장하지 않습니다 . 오히려 술을 마시면 건강이 악화될 수 있으니 적당한 양을 지키며 , 건강한 생활습관을 유지하는 것이 중요합니다 .\n",
      "[Gen   ] 무엇이 문제인지 자세한 설명을 해주시면 답변을 드릴 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for prompt, ref, pred in zip(inputs, ref_labels, ppo_pred_texts):\n",
    "    print()\n",
    "    print(\"[Prompt]\", prompt)\n",
    "    print(\"[Ref   ]\", ref)\n",
    "    print(\"[Gen   ]\", pred)\n",
    "    cnt +=1\n",
    "    if cnt >= 5 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48647726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 ROUGE 점수\n",
      "ROUGE-1 F1: 0.1626\n",
      "ROUGE-2 F1: 0.0644\n",
      "ROUGE-L F1: 0.1606\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_rouge(ref_labels, ppo_pred_texts )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c52d29b",
   "metadata": {},
   "source": [
    "## SFT only 모델의 generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "719b3a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 1000/1000 [50:07<00:00,  3.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "저는 인공지능 어시스턴트이기 때문에 서브 스피드의 속도와 관련된 정보를 알 수 없습니다. 죄송합니다.\n",
      "\n",
      "저는 인공지능 어시스턴트이기 때문에 서브 스피드의 속도와 관련된 정보를 알 수 없습니다. 죄송합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 허깅페이스의 pipleline 클래스를 사용하여 generator 생성\n",
    "sft_generator = pipeline('text-generation', model='./modles/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=tokenizer.eos_token_id, #375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sft_results = []\n",
    "for input_text in tqdm(inputs, desc=\"Generating\"):\n",
    "    result = sft_generator(input_text, **generation_args)\n",
    "    sft_results.append(result)\n",
    "\n",
    "\n",
    "sft_pred_texts = [\n",
    "    r[0][\"generated_text\"].split(\"### Response(응답):\")[-1].strip()\n",
    "    for r in sft_results\n",
    "    ]\n",
    "\n",
    "    \n",
    "print(len(sft_pred_texts))\n",
    "\n",
    "print(sft_pred_texts[0])\n",
    "print()\n",
    "print(sft_pred_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adbf52a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '### Instruction(명령어):\\n최고 서브 스피드 속도가 얼마나 되지\\n\\n### Response(응답):저는 인공지능 어시스턴트이기 때문에 서브 스피드의 속도와 관련된 정보를 알 수 없습니다. 죄송합니다.'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(sft_results))\n",
    "sft_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee2c9887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "최고 서브 스피드 속도가 얼마나 되지\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 저는 인공지능 언어모델입니다 . 서브 스피드 라는 용어가 정확히 어떤 것인지 알 수 없어서 답변해드리기 어렵습니다 . 더 자세한 정보를 제공해주시면 답변 드릴 수 있습니다 . 감사합니다 .\n",
      "[Gen   ] 저는 인공지능 어시스턴트이기 때문에 서브 스피드의 속도와 관련된 정보를 알 수 없습니다. 죄송합니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "라울이 레알마드리드에서 몇 골 넣었어\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 요즘은 레알 마드리드에서 뛰지 않는 라울 곤잘레스의 경우 , 2010 11 시즌 동안 레알 마드리드에서 13골을 넣었다 .\n",
      "[Gen   ] 저는 라울의 골 수를 알 수 없습니다. 라울은 현재 리버풀 fc에서 뛰고 있으며, 공격수나 수비수 등 다양한 분야에서 활약하고 있습니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "여기 얼마에요 ?\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 저는 가격을 알 수 없습니다 . 제가 할 수 있는 것은 대화나 자연어 이해에 대한 질문에 답변하는 것입니다 . 상황에 따라 가격이 달라질 수 있으므로 , 판매자나 가게 직원에게 직접 가격을 문의해보시는 것이 좋습니다 .\n",
      "[Gen   ] 죄송합니다, 저는 가격을 알 수 없습니다. 어떤 상품에 대해 문의하시는 건가요?\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "마리 앙투아네트는 프랑스와의 동맹을 위해 누구와 정략결혼을 했는가 ?\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 마리 앙투아네트는 오스트리아의 황자인 프란츠 요셉과 정략결혼을 했습니다 .\n",
      "[Gen   ] 마리 앙투아네트 는 프랑스와의 동맹을 강화하기 위해 앙리 4세, 마리 앙투아네트와 함께 결혼했습니다.\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "술이 보약도 아니고\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 건강에 해롭기 때문에 권장하지 않습니다 . 오히려 술을 마시면 건강이 악화될 수 있으니 적당한 양을 지키며 , 건강한 생활습관을 유지하는 것이 중요합니다 .\n",
      "[Gen   ] 저는 ai 어시스턴트이기 때문에 술을 마시지 않습니다. 하지만, 술에 취하지 않도록 주의해 주세요.\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for prompt, ref, pred in zip(inputs, ref_labels, sft_pred_texts):\n",
    "    print()\n",
    "    print(\"[Prompt]\", prompt)\n",
    "    print(\"[Ref   ]\", ref)\n",
    "    print(\"[Gen   ]\", pred)\n",
    "    cnt +=1\n",
    "    if cnt >= 5 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17bf2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 ROUGE 점수\n",
      "ROUGE-1 F1: 0.2017\n",
      "ROUGE-2 F1: 0.0869\n",
      "ROUGE-L F1: 0.1994\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_rouge(ref_labels, sft_pred_texts )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a154ab1a",
   "metadata": {},
   "source": [
    "# <회고>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1a83f",
   "metadata": {},
   "source": [
    "## 실험 기록 \n",
    "1. SFT와 generation 비교를 하려면, SFT 훈련을 하지 않은 test_dataset (마지막 1000건)으로 비교하자!\n",
    "2. 저장된 PPO pretrained model을 불러와서 generator를 쓰려고 해봤는데..... \n",
    "3. 1000건 generate에 약 1시간 소요\n",
    "\n",
    "4. RM 훈련을 ranking 0-1, 0-2 set로 훈련했는데, ranking 0-1, 0-2, 1-2 set로 다시 훈련해보자\n",
    "   -> 별 영향 없음 \n",
    "5. Eearly_stopping 옵션을 주지 않으면 max_length까지 출력해서 쓸데없는 내용들이 많이 붙어 있다 \n",
    "   -> early_stopping 추가 후, PPO의 rouge값이 조금 개선됨. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b57d76",
   "metadata": {},
   "source": [
    "### 루브릭 1.  KoGPT와 SFT 모델  결과를 정량/정성적으로 비교\n",
    "\n",
    "✅ koChatGPT_SFT 파일 참고\n",
    "\n",
    " - KoGTP가 SFT보다 ROUGE 점수는 더 좋게 나왔으나, SFT가 더 자연스러운 문장을 생성한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a5e0d",
   "metadata": {},
   "source": [
    "### 루브릭 2. SFT 모델의 결과와 PPO 모델 결과를 정량/정성적으로 비교\n",
    "- SFT만 한 모델의 genereate와  SFT+RM 한 PPO 모델의 generate \n",
    "\n",
    "✅ ROUGE 점수\n",
    "\n",
    "| Metric  | PPO F1 Score | SFT F1 Score |\n",
    "| ------- | ------------ |------------- |\n",
    "| ROUGE-1 | 0.1626       |  0.2017      |\n",
    "| ROUGE-2 | 0.0644       |  0.0869      |\n",
    "| ROUGE-L | 0.1606       |  0.1994      |\n",
    "\n",
    "✅ Response 생성 능력 \n",
    " \n",
    "- SFT, PPO 둘다 자연스럽고 필요한 문장으로 출력되는데, SFT가 좀 더 필요한 내용으로만 출력된다. \n",
    "- PPO는 문장이 반복되는 느낌이 있다. (이는 reward에서 높은 점수를 주는 패턴을 반복학습해서 생기는 현상일 수 있다. ) \n",
    "\n",
    "\n",
    "✅ ROUGE 점수가 낮은 이유\n",
    " - ROUTE는 단순히 n-gram 중첩률을 보므로, 문장이 그럴듯하게 생성되어도, reference에 있는 단어들과 중첩이 적으면 점수가 낮게 나온다. \n",
    " - ROUGE는 특히 reference에 있는 핵심 키워드가 생성 결과에 엄라나 포함되었는지를 측정한다. \n",
    " - PPO 학습은 사람의 피드백으로 학습된 것이라서, 의미 일치보다는 자연스러움에 더 강하다. \n",
    " \n",
    "✅ 생각해 볼것 \n",
    " - 자연스럼움 + 정확성 필요함. \"정확성\"을 높이려면 학습 데이타가 더 많아야 할까?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682ea9a",
   "metadata": {},
   "source": [
    "### 루브릭 3. 정량적 성능 향상\n",
    "1. 기존 데이터셋을 추가로 정제하고, beam-search, top-k sampling등 generation 성능을 올리기 위한 기법을 적용하여 시험해 모델 성능을 향상시켰다. \n",
    "\n",
    "✅ 데이터셋 정제 : KoChatGPT_eda 파일 참고 \n",
    "  - 데이터 정제 및 불필요한 데이터 삭제\n",
    "  - ranking이 맞지 않는 RM 데이타 존재\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e884878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.12.1\n",
      "Cuda version: 11.3\n",
      "transformers version: 4.28.0\n",
      "GPU 사용 가능여부: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Torch version:{}\".format(torch.__version__)) # Torch version:1.12.1\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda)) # Cuda version: 11.3\n",
    "print(\"transformers version: {}\".format(transformers.__version__)) # transformers 4.28.0\n",
    "print(\"GPU 사용 가능여부: {}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1b77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e23bffff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba4da1",
   "metadata": {},
   "source": [
    "# 0. 전처리된 데이타 파일 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1331ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save_path_SFT = './data/clean_kochatgpt_1_SFT.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec0b83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#with open(data_save_path_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "#    sft_data_dict = json.load(json_file)\n",
    "\n",
    "#print(len(sft_data_dict))\n",
    "#sft_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb763f",
   "metadata": {},
   "source": [
    "# 1. KOGPT2 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f50c00a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)  # GPU 또는 CPU\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    "    #model_max_length=384,           # CUDA OOM 문제로 줄여보자!!\n",
    ")\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb34e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        # batch 내 label 시퀀스를 길이에 맞춰 패딩(padding)\n",
    "        # padding_value= -100 : 짧은 시퀀스를 맞추기 위해 채울 값\n",
    "        # PyTorch의 nn.CrossEntropyLoss()에서는 ignore_index=-100이 기본값\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44b2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoGPT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(KoGPT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        sources = []\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            sources.append(example['prompt'])\n",
    "            targets.append(example['completion'] + tokenizer.eos_token)\n",
    "          \n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        # sources_tokenized는 **입력 마스킹(masking)**에 쓰이고,\n",
    "        # examples_tokenized는 전체 학습 텍스트 + 레이블용 토큰이다\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        # loss 계산시 label을 정의하는 부분으로, input_ids를 그대로 copy하되\n",
    "        # prompt 부분은 필요없으므로 lable에서 prompt 부분은 -100으로 masking한다. \n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "       \n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1668d1ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 11992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.KoGPT_dataset'>\n",
      "11992\n",
      "input : tensor([ 9128, 20479,  8091, 22311,  9036, 30902,  8084,   739,   406, 37767,\n",
      "        13753,  8263,  7166,   739,  8352,  7659,  9639, 11481, 25585, 13600,\n",
      "         8022,  9378, 11532,  9887, 11218,  9111, 16913,  7182, 36510, 10351,\n",
      "        10561,  9128, 20479,  8091,  9065,  9446, 33869, 11481, 46311, 11481,\n",
      "        26367,  6958,  9030,  9882, 12317, 25882,  9209,  8708,  7172,  7182,\n",
      "        36510, 10351,  9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188,\n",
      "         9355, 11481,  9036, 15805, 11300, 11846,  9146, 16913,  7182, 36510,\n",
      "         9181,  7397, 15806, 13480, 11342, 17596,  9161, 19996,  9025, 25006,\n",
      "        18595,  9966, 12592, 10751, 11814,  8711,  9046, 12450,  9117,  7377,\n",
      "         7172,  7182, 36510,     1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 37767,\n",
      "        13753,  8263,  7166,   739,  8352,  7659,  9639, 11481, 25585, 13600,\n",
      "         8022,  9378, 11532,  9887, 11218,  9111, 16913,  7182, 36510, 10351,\n",
      "        10561,  9128, 20479,  8091,  9065,  9446, 33869, 11481, 46311, 11481,\n",
      "        26367,  6958,  9030,  9882, 12317, 25882,  9209,  8708,  7172,  7182,\n",
      "        36510, 10351,  9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188,\n",
      "         9355, 11481,  9036, 15805, 11300, 11846,  9146, 16913,  7182, 36510,\n",
      "         9181,  7397, 15806, 13480, 11342, 17596,  9161, 19996,  9025, 25006,\n",
      "        18595,  9966, 12592, 10751, 11814,  8711,  9046, 12450,  9117,  7377,\n",
      "         7172,  7182, 36510,     1])\n"
     ]
    }
   ],
   "source": [
    "kg_train_dataset = KoGPT_dataset(data_path_1_SFT=data_save_path_SFT, tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print(type(kg_train_dataset))\n",
    "print(len(kg_train_dataset))\n",
    "print('input : %s'%kg_train_dataset.input_ids[0])\n",
    "print('output: %s'%kg_train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81148257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  501216 KB |  501216 KB |  501216 KB |       0 B  |\n",
      "|       from large pool |  488448 KB |  488448 KB |  488448 KB |       0 B  |\n",
      "|       from small pool |   12768 KB |   12768 KB |   12768 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  501216 KB |  501216 KB |  501216 KB |       0 B  |\n",
      "|       from large pool |  488448 KB |  488448 KB |  488448 KB |       0 B  |\n",
      "|       from small pool |   12768 KB |   12768 KB |   12768 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  557056 KB |  557056 KB |  557056 KB |       0 B  |\n",
      "|       from large pool |  542720 KB |  542720 KB |  542720 KB |       0 B  |\n",
      "|       from small pool |   14336 KB |   14336 KB |   14336 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   55840 KB |   55849 KB |  269821 KB |  213981 KB |\n",
      "|       from large pool |   54272 KB |   54272 KB |  261632 KB |  207360 KB |\n",
      "|       from small pool |    1568 KB |    2045 KB |    8189 KB |    6621 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     172    |     172    |     172    |       0    |\n",
      "|       from large pool |      50    |      50    |      50    |       0    |\n",
      "|       from small pool |     122    |     122    |     122    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     172    |     172    |     172    |       0    |\n",
      "|       from large pool |      50    |      50    |      50    |       0    |\n",
      "|       from small pool |     122    |     122    |     122    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      27    |      27    |      27    |       0    |\n",
      "|       from large pool |      20    |      20    |      20    |       0    |\n",
      "|       from small pool |       7    |       7    |       7    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      21    |      21    |      26    |       5    |\n",
      "|       from large pool |      19    |      19    |      19    |       0    |\n",
      "|       from small pool |       2    |       2    |       7    |       5    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9748e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INPUT]:\n",
      "불고기용 고기 한우에요?저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\n",
      "\n",
      "[LABEL]:\n",
      "저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_dataset.input_ids[0]를 디코딩해보세요.\n",
    "input_text = tokenizer.decode(kg_train_dataset.input_ids[0] , skip_special_tokens=True)\n",
    "label_text = tokenizer.decode([token for token in  kg_train_dataset.labels[0]  if token != -100], skip_special_tokens=True)\n",
    "\n",
    "print(f\"[INPUT]:\\n{input_text}\\n\")\n",
    "print(f\"[LABEL]:\\n{label_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8991e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9593\n",
      "Validation: 1199\n",
      "Test: 1200\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "total_len = len(kg_train_dataset)\n",
    "\n",
    "# train 80%, val 10%, test 10%로 나누기\n",
    "train_size = int(0.8 * total_len)\n",
    "val_size = int(0.1 * total_len)\n",
    "test_size = total_len - train_size - val_size  # 남는 거 처리\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "kg_train, kg_val, kg_test = random_split(kg_train_dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "\n",
    "print(f\"Train: {len(kg_train)}\")\n",
    "print(f\"Validation: {len(kg_val)}\")\n",
    "print(f\"Test: {len(kg_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5c0c1",
   "metadata": {},
   "source": [
    "**Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34be41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    # shift so that tokens <n> predict <n+1>\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "    # Flatten for loss calculation\n",
    "    loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    \n",
    "    # Perplexity\n",
    "    perplexity = math.exp(loss.item())\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss.item(),\n",
    "        \"perplexity\": perplexity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0612553",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.getenv('HOME')+'/aiffel/KoChatGPT/test'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",        #evaluation하는 빈도\n",
    "    logging_strategy=\"epoch\",           # epoch마다 로그 기록\n",
    "    learning_rate = 2e-5,               #learning_rate\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    warmup_steps=5,\n",
    "    #prediction_loss_only=True,\n",
    "    logging_dir=\"./kogpt_logs\",\n",
    "    fp16 = True\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    \n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=kg_train,\n",
    "    eval_dataset=kg_val, \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b092f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='934' max='4797' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 934/4797 02:43 < 11:18, 5.69 it/s, Epoch 0.19/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0744b7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='996' max='996' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [996/996 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.3260583877563477,\n",
       " 'eval_runtime': 20.2746,\n",
       " 'eval_samples_per_second': 98.251,\n",
       " 'eval_steps_per_second': 49.125,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(kg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d3b105e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000, Epoch: 1.0, Loss: 2.5694\n",
      "Step: 5000, Epoch: 1.0, Eval Loss: 2.3260583877563477\n"
     ]
    }
   ],
   "source": [
    "for log in trainer.state.log_history:\n",
    "    if 'eval_loss' in log:\n",
    "        print(f\"Step: {log.get('step')}, Epoch: {log.get('epoch')}, Eval Loss: {log.get('eval_loss')}\")\n",
    "    if 'loss' in log:\n",
    "        print(f\"Step: {log.get('step')}, Epoch: {log.get('epoch')}, Loss: {log.get('loss')}\")\n",
    "    if 'perplexity' in log:\n",
    "        print(f\"Step: {log.get('step')}, Epoch: {log.get('epoch')}, Perplexity: {log.get('perplexity')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90b4c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_train_graph(logs) : \n",
    "    train_loss = [log[\"loss\"] for log in logs if \"loss\" in log]\n",
    "    steps = list(range(1, len(train_loss) + 1))\n",
    "    \n",
    "    eval_loss = [log[\"eval_loss\"] for log in logs if \"eval_loss\" in log]\n",
    "    #eval_acc = [log[\"eval_accuracy\"] for log in logs if \"eval_accuracy\" in log]\n",
    "    #eval_f1 = [log[\"eval_f1\"] for log in logs if \"eval_f1\" in log]\n",
    "    # eval_steps = list(range(1, len(eval_loss)) )\n",
    "    \n",
    "    # train_loss 길이에 맞춰 eval_loss, eval_acc, eval_f1 자르기\n",
    "    eval_loss = eval_loss[:len(train_loss)]\n",
    "    #eval_acc = eval_acc[:len(train_loss)]\n",
    "    #eval_f1 = eval_f1[:len(train_loss)]\n",
    "    eval_steps = steps\n",
    "\n",
    "    # 그래프 그리기\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss 그래프\n",
    "    \n",
    "    plt.plot(steps, train_loss, label=\"Train Loss\") \n",
    "    plt.plot(steps, eval_loss, label=\"Val Loss\", color=\"red\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Train Loss per Epoch\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "869848f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 후 로그 가져오기\n",
    "kogpt_logs = trainer.state.log_history\n",
    "\n",
    "display_train_graph(logs = kogpt_logs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

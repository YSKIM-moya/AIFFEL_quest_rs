{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac1adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.12.1\n",
      "Cuda version: 11.3\n",
      "transformers version: 4.28.0\n",
      "GPU 사용 가능여부: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Torch version:{}\".format(torch.__version__)) # Torch version:1.12.1\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda)) # Cuda version: 11.3\n",
    "print(\"transformers version: {}\".format(transformers.__version__)) # transformers 4.28.0\n",
    "print(\"GPU 사용 가능여부: {}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb81c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68009bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8a90dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300cd1af",
   "metadata": {},
   "source": [
    "# 0. 전처리된 데이타 파일 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f81cec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save_path_SFT = './data/clean_kochatgpt_1_SFT.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bddebca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#with open(data_save_path_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "#    sft_data_dict = json.load(json_file)\n",
    "\n",
    "#print(len(sft_data_dict))\n",
    "#sft_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c66c5",
   "metadata": {},
   "source": [
    "## 공통 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e509dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    # shift so that tokens <n> predict <n+1>\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "    # Flatten for loss calculation\n",
    "    loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    \n",
    "    # Perplexity\n",
    "    perplexity = math.exp(loss.item())\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss.item(),\n",
    "        \"perplexity\": perplexity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c5a14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_train_graph(logs) : \n",
    "    \n",
    "    for log in logs:\n",
    "        if 'eval_loss' in log:\n",
    "            print(f\"Step: {log.get('step')}, Epoch: {log.get('epoch')}, Eval Loss: {log.get('eval_loss')}\")\n",
    "        if 'loss' in log:\n",
    "            print(f\"Step: {log.get('step')}, Epoch: {log.get('epoch')}, Loss: {log.get('loss')}\")\n",
    "        if 'perplexity' in log:\n",
    "            print(f\"Step: {log.get('step')}, Epoch: {log.get('epoch')}, Perplexity: {log.get('perplexity')}\")\n",
    "    \n",
    "    \n",
    "    train_loss = [log[\"loss\"] for log in logs if \"loss\" in log]\n",
    "    steps = list(range(1, len(train_loss) + 1))\n",
    "    \n",
    "    eval_loss = [log[\"eval_loss\"] for log in logs if \"eval_loss\" in log]\n",
    "    #eval_acc = [log[\"eval_accuracy\"] for log in logs if \"eval_accuracy\" in log]\n",
    "    #eval_f1 = [log[\"eval_f1\"] for log in logs if \"eval_f1\" in log]\n",
    "    # eval_steps = list(range(1, len(eval_loss)) )\n",
    "    \n",
    "    # train_loss 길이에 맞춰 eval_loss, eval_acc, eval_f1 자르기\n",
    "    eval_loss = eval_loss[:len(train_loss)]\n",
    "    #eval_acc = eval_acc[:len(train_loss)]\n",
    "    #eval_f1 = eval_f1[:len(train_loss)]\n",
    "    eval_steps = steps\n",
    "\n",
    "    # 그래프 그리기\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss 그래프\n",
    "    \n",
    "    plt.plot(steps, train_loss, label=\"Train Loss\") \n",
    "    plt.plot(steps, eval_loss, label=\"Val Loss\", color=\"red\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Train Loss per Epoch\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01cc53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_rouge(refs, preds): \n",
    "    rouge = Rouge()\n",
    "    all_scores = []\n",
    "    results = []\n",
    "    \n",
    "    for ref, pred in zip(refs, preds):\n",
    "        if ref.strip() == \"\" or pred.strip() == \"\":\n",
    "            continue\n",
    "        \n",
    "        score = rouge.get_scores(pred, ref)[0]\n",
    "        all_scores.append(score)\n",
    "        \n",
    "        results.append({\n",
    "            'ROUGE-1': score['rouge-1']['f'],\n",
    "            'ROUGE-2': score['rouge-2']['f'],\n",
    "            'ROUGE-L': score['rouge-l']['f']\n",
    "        })\n",
    "    \n",
    "    # 평균값\n",
    "    rouge_1 = np.mean([s['rouge-1']['f'] for s in all_scores])\n",
    "    rouge_2 = np.mean([s['rouge-2']['f'] for s in all_scores])\n",
    "    rouge_l = np.mean([s['rouge-l']['f'] for s in all_scores])\n",
    "    \n",
    "    print(\"📊 평균 ROUGE 점수\")\n",
    "    print(f\"ROUGE-1 F1: {rouge_1:.4f}\")\n",
    "    print(f\"ROUGE-2 F1: {rouge_2:.4f}\")\n",
    "    print(f\"ROUGE-L F1: {rouge_l:.4f}\") \n",
    "    \n",
    "    # 그래프\n",
    "    df = pd.DataFrame(results)\n",
    " \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=df[['ROUGE-1', 'ROUGE-2', 'ROUGE-L']])\n",
    "    plt.title(\"ROUGE Score Distribution\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22c6ce",
   "metadata": {},
   "source": [
    "# 1. KOGPT2 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4849270e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=384, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)  # GPU 또는 CPU\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    #model_max_length=512,\n",
    "    model_max_length=384,           # CUDA OOM 문제로 줄여보자!!\n",
    ")\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed577e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        # batch 내 label 시퀀스를 길이에 맞춰 패딩(padding)\n",
    "        # padding_value= -100 : 짧은 시퀀스를 맞추기 위해 채울 값\n",
    "        # PyTorch의 nn.CrossEntropyLoss()에서는 ignore_index=-100이 기본값\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7755881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoGPT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(KoGPT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        sources = []\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            sources.append(example['prompt'])\n",
    "            targets.append(example['completion'] + tokenizer.eos_token)\n",
    "          \n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        # sources_tokenized는 **입력 마스킹(masking)**에 쓰이고,\n",
    "        # examples_tokenized는 전체 학습 텍스트 + 레이블용 토큰이다\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        source_ids = sources_tokenized[\"input_ids\"]\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        # loss 계산시 label을 정의하는 부분으로, input_ids를 그대로 copy하되\n",
    "        # prompt 부분은 필요없으므로 lable에서 prompt 부분은 -100으로 masking한다. \n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "       \n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels, source_ids=source_ids)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        self.source_ids = data_dict[\"source_ids\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i], source_ids=self.source_ids[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db1cc0f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 11992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.KoGPT_dataset'>\n",
      "11992\n",
      "input : tensor([ 9128, 20479,  8091, 22311,  9036, 30902,  8084,   739,   406, 37767,\n",
      "        13753,  8263,  7166,   739,  8352,  7659,  9639, 11481, 25585, 13600,\n",
      "         8022,  9378, 11532,  9887, 11218,  9111, 16913,  7182, 36510, 10351,\n",
      "        10561,  9128, 20479,  8091,  9065,  9446, 33869, 11481, 46311, 11481,\n",
      "        26367,  6958,  9030,  9882, 12317, 25882,  9209,  8708,  7172,  7182,\n",
      "        36510, 10351,  9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188,\n",
      "         9355, 11481,  9036, 15805, 11300, 11846,  9146, 16913,  7182, 36510,\n",
      "         9181,  7397, 15806, 13480, 11342, 17596,  9161, 19996,  9025, 25006,\n",
      "        18595,  9966, 12592, 10751, 11814,  8711,  9046, 12450,  9117,  7377,\n",
      "         7172,  7182, 36510,     1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 37767,\n",
      "        13753,  8263,  7166,   739,  8352,  7659,  9639, 11481, 25585, 13600,\n",
      "         8022,  9378, 11532,  9887, 11218,  9111, 16913,  7182, 36510, 10351,\n",
      "        10561,  9128, 20479,  8091,  9065,  9446, 33869, 11481, 46311, 11481,\n",
      "        26367,  6958,  9030,  9882, 12317, 25882,  9209,  8708,  7172,  7182,\n",
      "        36510, 10351,  9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188,\n",
      "         9355, 11481,  9036, 15805, 11300, 11846,  9146, 16913,  7182, 36510,\n",
      "         9181,  7397, 15806, 13480, 11342, 17596,  9161, 19996,  9025, 25006,\n",
      "        18595,  9966, 12592, 10751, 11814,  8711,  9046, 12450,  9117,  7377,\n",
      "         7172,  7182, 36510,     1])\n",
      "source: tensor([ 9128, 20479,  8091, 22311,  9036, 30902,  8084,   739,   406])\n"
     ]
    }
   ],
   "source": [
    "kg_train_dataset = KoGPT_dataset(data_path_1_SFT=data_save_path_SFT, tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print(type(kg_train_dataset))\n",
    "print(len(kg_train_dataset))\n",
    "print('input : %s'%kg_train_dataset.input_ids[0])\n",
    "print('output: %s'%kg_train_dataset.labels[0])\n",
    "print('source: %s'%kg_train_dataset.source_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32dee3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  501216 KB |  501216 KB |  501216 KB |       0 B  |\n",
      "|       from large pool |  488448 KB |  488448 KB |  488448 KB |       0 B  |\n",
      "|       from small pool |   12768 KB |   12768 KB |   12768 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  501216 KB |  501216 KB |  501216 KB |       0 B  |\n",
      "|       from large pool |  488448 KB |  488448 KB |  488448 KB |       0 B  |\n",
      "|       from small pool |   12768 KB |   12768 KB |   12768 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  557056 KB |  557056 KB |  557056 KB |       0 B  |\n",
      "|       from large pool |  542720 KB |  542720 KB |  542720 KB |       0 B  |\n",
      "|       from small pool |   14336 KB |   14336 KB |   14336 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   55840 KB |   55849 KB |  269821 KB |  213981 KB |\n",
      "|       from large pool |   54272 KB |   54272 KB |  261632 KB |  207360 KB |\n",
      "|       from small pool |    1568 KB |    2045 KB |    8189 KB |    6621 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     172    |     172    |     172    |       0    |\n",
      "|       from large pool |      50    |      50    |      50    |       0    |\n",
      "|       from small pool |     122    |     122    |     122    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     172    |     172    |     172    |       0    |\n",
      "|       from large pool |      50    |      50    |      50    |       0    |\n",
      "|       from small pool |     122    |     122    |     122    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      27    |      27    |      27    |       0    |\n",
      "|       from large pool |      20    |      20    |      20    |       0    |\n",
      "|       from small pool |       7    |       7    |       7    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      21    |      21    |      26    |       5    |\n",
      "|       from large pool |      19    |      19    |      19    |       0    |\n",
      "|       from small pool |       2    |       2    |       7    |       5    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       1    |       1    |       1    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10c64a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INPUT]:\n",
      "불고기용 고기 한우에요?저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\n",
      "\n",
      "[LABEL]:\n",
      "저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\n",
      "\n",
      "[PROMPT]:\n",
      "불고기용 고기 한우에요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_dataset.input_ids[0]를 디코딩해보세요.\n",
    "input_text = tokenizer.decode(kg_train_dataset.input_ids[0] , skip_special_tokens=True)\n",
    "label_text = tokenizer.decode([token for token in  kg_train_dataset.labels[0]  if token != -100], skip_special_tokens=True)\n",
    "prompt_text = tokenizer.decode(kg_train_dataset.source_ids[0] , skip_special_tokens=True)\n",
    "\n",
    "print(f\"[INPUT]:\\n{input_text}\\n\")\n",
    "print(f\"[LABEL]:\\n{label_text}\\n\")\n",
    "print(f\"[PROMPT]:\\n{prompt_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e958588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9593\n",
      "Validation: 1199\n",
      "Test: 1200\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "total_len = len(kg_train_dataset)\n",
    "\n",
    "# train 80%, val 10%, test 10%로 나누기\n",
    "train_size = int(0.8 * total_len)\n",
    "val_size = int(0.1 * total_len)\n",
    "test_size = total_len - train_size - val_size  # 남는 거 처리\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(kg_train_dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Validation: {len(val_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8a414",
   "metadata": {},
   "source": [
    "**Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "080b970a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 9202,  7536, 12622, 17885,  7661,   392, 36510, 14553, 10667,  9867,\n",
       "         49165,  9067, 10233,  9117,  7748,  9173,  9290, 12519, 14553, 10667,\n",
       "          9867,  9316,  9202,  9883,  9337,  9025,  9019, 16913,  7182, 36510,\n",
       "          9045, 36510,  9032, 13041,  9183,  9677, 11117, 26512, 18026,  9183,\n",
       "          9677, 11117, 49165,  9067, 10002, 11312,  8137,  9350, 19377,  9202,\n",
       "          9883,  9337,  9025,  9019, 16913,  7182, 36510,  9085, 36510, 24878,\n",
       "         12222, 11814,  8718, 10247, 11018,  7055, 15454,  9337,  9068, 45568,\n",
       "         17437,  7055, 14795, 18422, 11814,  9328, 27728, 11312,  9956, 11615,\n",
       "         23523,  9202,  9883,  9337,  9025,  9019, 16913,  7182, 36510,  9130,\n",
       "         36510, 11342,  9694, 12519, 11342, 32563, 10407, 49165,  9067, 10002,\n",
       "         11312,  9956, 11615, 23523,  9202,  9883,  9337,  9025,  9019, 16913,\n",
       "          7182, 36510,  9143, 36510,  9306, 12519, 10407, 13814,  8420, 11335,\n",
       "         49165, 22364, 10407, 49165,  9067, 10002, 11312,  9956, 11615, 23523,\n",
       "          9202,  9883,  9337,  9025,  9019, 16913,  7182, 36510,     1]),\n",
       " 'labels': tensor([ -100,  -100,  -100,  -100,  -100,   392, 36510, 14553, 10667,  9867,\n",
       "         49165,  9067, 10233,  9117,  7748,  9173,  9290, 12519, 14553, 10667,\n",
       "          9867,  9316,  9202,  9883,  9337,  9025,  9019, 16913,  7182, 36510,\n",
       "          9045, 36510,  9032, 13041,  9183,  9677, 11117, 26512, 18026,  9183,\n",
       "          9677, 11117, 49165,  9067, 10002, 11312,  8137,  9350, 19377,  9202,\n",
       "          9883,  9337,  9025,  9019, 16913,  7182, 36510,  9085, 36510, 24878,\n",
       "         12222, 11814,  8718, 10247, 11018,  7055, 15454,  9337,  9068, 45568,\n",
       "         17437,  7055, 14795, 18422, 11814,  9328, 27728, 11312,  9956, 11615,\n",
       "         23523,  9202,  9883,  9337,  9025,  9019, 16913,  7182, 36510,  9130,\n",
       "         36510, 11342,  9694, 12519, 11342, 32563, 10407, 49165,  9067, 10002,\n",
       "         11312,  9956, 11615, 23523,  9202,  9883,  9337,  9025,  9019, 16913,\n",
       "          7182, 36510,  9143, 36510,  9306, 12519, 10407, 13814,  8420, 11335,\n",
       "         49165, 22364, 10407, 49165,  9067, 10002, 11312,  9956, 11615, 23523,\n",
       "          9202,  9883,  9337,  9025,  9019, 16913,  7182, 36510,     1]),\n",
       " 'source_ids': tensor([ 9202,  7536, 12622, 17885,  7661])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e15cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.getenv('HOME')+'/aiffel/KoChatGPT/test'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",        #evaluation하는 빈도\n",
    "    logging_strategy=\"epoch\",           # epoch마다 로그 기록\n",
    "    learning_rate = 2e-5,               #learning_rate\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,  # CUDA OOM하고 연관 있나?\n",
    "    logging_dir=\"./kogpt_logs\",\n",
    "    fp16 = True\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    \n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset, \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe924192",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.getenv('HOME')+'/aiffel/KoChatGPT/test'\n",
    "\n",
    "#training_args = TrainingArguments(\n",
    "    output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "059d6f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9593' max='9593' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9593/9593 33:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.556800</td>\n",
       "      <td>2.297744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('./modles/output_1_KoGPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5421f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c181055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9593, Epoch: 1.0, Loss: 2.5568\n",
      "Step: 9593, Epoch: 1.0, Eval Loss: 2.297744035720825\n"
     ]
    }
   ],
   "source": [
    "for log in trainer.state.log_history:\n",
    "    if 'eval_loss' in log:\n",
    "        print(f\"Step: {log.get('step')}, Epoch: {log.get('epoch')}, Eval Loss: {log.get('eval_loss')}\")\n",
    "    if 'loss' in log:\n",
    "        print(f\"Step: {log.get('step')}, Epoch: {log.get('epoch')}, Loss: {log.get('loss')}\")\n",
    "    if 'perplexity' in log:\n",
    "        print(f\"Step: {log.get('step')}, Epoch: {log.get('epoch')}, Perplexity: {log.get('perplexity')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dc5ec29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 후 로그 가져오기\n",
    "kogpt_logs = trainer.state.log_history\n",
    "\n",
    "display_train_graph(logs = kogpt_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd3696",
   "metadata": {},
   "source": [
    "**generate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468be916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11992\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = []\n",
    "for idx, data in enumerate(kg_train_dataset) : \n",
    "    input_ids = data['input_ids']\n",
    "    input_text = tokenizer.decode(input_ids , skip_special_tokens=True)\n",
    "    \n",
    "    inputs.append(input_text)\n",
    "    \n",
    "print(len(inputs))\n",
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2d9293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11992\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = []\n",
    "for idx, data in enumerate(kg_train_dataset) : \n",
    "    label_ids = data['labels']\n",
    "    label_text = tokenizer.decode([token for token in  label_ids  if token != -100], skip_special_tokens=True)\n",
    "    \n",
    "    labels.append(label_text)\n",
    "    \n",
    "print(len(labels))\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15bef86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 100/100 [04:55<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='./modles/output_1_KoGPT', tokenizer=tokenizer)\n",
    "#generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id= tokenizer.eos_token_id, #375, # \\n   \n",
    "    temperature=1.0,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "\n",
    "test_count = 100 # 개수를 줄여보자\n",
    "\n",
    "# inputs\n",
    "inputs = []\n",
    "for idx, data in enumerate(test_dataset) : \n",
    "    if idx >= test_count :\n",
    "        break\n",
    "    input_ids = data['source_ids']\n",
    "    input_text = tokenizer.decode(input_ids , skip_special_tokens=True)\n",
    "    \n",
    "    inputs.append(input_text)\n",
    "    \n",
    "print(len(inputs))\n",
    "\n",
    "\n",
    "# references \n",
    "ref_labels = []\n",
    "for idx, data in enumerate(test_dataset) : \n",
    "    if idx >= test_count :\n",
    "        break\n",
    "    label_ids = data['labels']\n",
    "    label_text = tokenizer.decode([token for token in  label_ids  if token != -100], skip_special_tokens=True)\n",
    "    \n",
    "    ref_labels.append(label_text)\n",
    "    \n",
    "print(len(ref_labels))\n",
    "\n",
    "\n",
    "# predictions \n",
    "#pred_results = generator(inputs, **generation_args)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pred_results = []\n",
    "for input_text in tqdm(inputs, desc=\"Generating\"):\n",
    "    result = generator(input_text, **generation_args)\n",
    "    pred_results.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6dfccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '변명거리 생각해봐제가 ai 챗봇이기 때문에, 어떤 문제가 있는지 자세히 설명해주시면 답변을 드릴 수 있을 것 같습니다.'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(pred_results))\n",
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "553b2ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Prompt] 변명거리 생각해봐\n",
      "[Ref   ] 1. 시간이 부족해서 일이나 공부가 바쁘다는 것을 이유로 시간이 부족해서라는 변명을 할 수 있습니다. 2. 기분이 안 좋아서 정신적인 상태가 안 좋아서 일이나 공부에 집중을 못하겠다는 변명을 할 수 있습니다. 3. 장소를 잘못 선택했어서 공부나 작업을 할 때 조용한 장소나 적절한 공간을 선택하지 않아서 집중력이 떨어졌다는 변명을 할 수 있습니다. 4. 건강상의 이유로 건강문제로 인해 일이나 공부에 집중력이 떨어졌다는 변명을 할 수 있습니다. 5. 다른 이유로 인해 예상치 못한 일이나 사건으로 인해 일이나 공부에 집중력이 떨어졌다는 변명을 할 수 있습니다.\n",
      "[Gen   ] 변명거리 생각해봐제가 ai 챗봇이기 때문에, 어떤 문제가 있는지 자세히 설명해주시면 답변을 드릴 수 있을 것 같습니다.\n",
      "\n",
      "[Prompt] 방탄소년단은 한국 가수 최초로 몇 개의 앨범이 연속으로 빌보드 200차트에 올랐나?\n",
      "[Ref   ] 방탄소년단은 5개의 앨범이 연속으로 빌보드 200차트에 올랐습니다. the most beautiful moment in life, part 2, the most beautiful moment in life young forever, wings, love yourself her, love yourself tear\n",
      "[Gen   ] 방탄소년단은 한국 가수 최초로 몇 개의 앨범이 연속으로 빌보드 200차트에 올랐나?방탄소년단은 2016년 발매한 방탄소년단의 앨범의 수록곡 중 하나인 방탄소년단 입니다., token 97\n",
      "\n",
      "[Prompt] boney m. 의 잠보 하쿠나 마타타를 부를 사람은?\n",
      "[Ref   ] boney m. 의 잠보 하쿠나 마타타를 부른 사람은 bobby farrell입니다.\n",
      "[Gen   ] boney m. 의 잠보 하쿠나 마타타를 부를 사람은?저는 ai 어시스턴트이기 때문에, 이 질문에 대한 답변을 제공할 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for prompt, ref, result in zip(inputs, ref_labels, pred_results):\n",
    "    print()\n",
    "    print(\"[Prompt]\", prompt)\n",
    "    print(\"[Ref   ]\", ref)\n",
    "    print(\"[Gen   ]\", (result[0]['generated_text']))\n",
    "    cnt +=1\n",
    "    if cnt >= 3 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de736c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 ROUGE 점수\n",
      "ROUGE-1 F1: 0.1404\n",
      "ROUGE-2 F1: 0.0647\n",
      "ROUGE-L F1: 0.1394\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_texts = [result[0][\"generated_text\"] for result in pred_results]\n",
    "\n",
    "compute_rouge(ref_labels, pred_texts )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317772be",
   "metadata": {},
   "source": [
    "# 2. SFT 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3458cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e26967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3e25ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1725e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        # sources_tokenized는 **입력 마스킹(masking)**에 쓰이고,\n",
    "        # examples_tokenized는 전체 학습 텍스트 + 레이블용 토큰이다\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        source_ids = sources_tokenized[\"input_ids\"]\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        # loss 계산시 label을 정의하는 부분으로, input_ids를 그대로 copy하되\n",
    "        # prompt 부분은 필요없으므로 lable에서 prompt 부분은 -100으로 masking한다. \n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "       \n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels, source_ids=source_ids)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        self.source_ids = data_dict[\"source_ids\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i], source_ids=self.source_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c3a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        # batch 내 label 시퀀스를 길이에 맞춰 패딩(padding)\n",
    "        # padding_value= -100 : 짧은 시퀀스를 맞추기 위해 채울 값\n",
    "        # PyTorch의 nn.CrossEntropyLoss()에서는 ignore_index=-100이 기본값\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c244ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 11992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.SFT_dataset'>\n",
      "11992\n",
      "input : tensor([  739,   378,   378,   378, 14659, 13394, 37091, 10651,   383, 25841,\n",
      "         8006, 14914,   375,  7673, 20479,  8091, 22311,  9036, 30902,  8084,\n",
      "          739, 10604,   375,   378,   378,   378, 41951,   454,  9549, 20549,\n",
      "          383,  8142,  7192, 14914, 37767, 13753,  8263,  7166,   739,  8352,\n",
      "         7659,  9639, 11481, 25585, 13600,  8022,  9378, 11532,  9887, 11218,\n",
      "         9111, 16913,  7182, 36510, 10351, 10561,  9128, 20479,  8091,  9065,\n",
      "         9446, 33869, 11481, 46311, 11481, 26367,  6958,  9030,  9882, 12317,\n",
      "        25882,  9209,  8708,  7172,  7182, 36510, 10351,  9036, 12168, 10529,\n",
      "        15989,  9719, 15434, 10552, 11188,  9355, 11481,  9036, 15805, 11300,\n",
      "        11846,  9146, 16913,  7182, 36510,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377,  7172,  7182, 36510,     1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100, 37767, 13753,  8263,  7166,   739,  8352,\n",
      "         7659,  9639, 11481, 25585, 13600,  8022,  9378, 11532,  9887, 11218,\n",
      "         9111, 16913,  7182, 36510, 10351, 10561,  9128, 20479,  8091,  9065,\n",
      "         9446, 33869, 11481, 46311, 11481, 26367,  6958,  9030,  9882, 12317,\n",
      "        25882,  9209,  8708,  7172,  7182, 36510, 10351,  9036, 12168, 10529,\n",
      "        15989,  9719, 15434, 10552, 11188,  9355, 11481,  9036, 15805, 11300,\n",
      "        11846,  9146, 16913,  7182, 36510,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377,  7172,  7182, 36510,     1])\n"
     ]
    }
   ],
   "source": [
    "data_save_path_SFT = './data/clean_kochatgpt_1_SFT.jsonl'\n",
    "\n",
    "all_train_dataset = SFT_dataset(data_path_1_SFT=data_save_path_SFT, tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print(type(all_train_dataset))\n",
    "print(len(all_train_dataset))\n",
    "print('input : %s'%all_train_dataset.input_ids[0])\n",
    "print('output: %s'%all_train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ef9438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9593\n",
      "Validation: 1199\n",
      "Test: 1200\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "total_len = len(all_train_dataset)\n",
    "\n",
    "# train 80%, val 10%, test 10%로 나누기\n",
    "train_size = int(0.8 * total_len)\n",
    "val_size = int(0.1 * total_len)\n",
    "test_size = total_len - train_size - val_size  # 남는 거 처리\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(all_train_dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Validation: {len(val_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a217bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.getenv('HOME')+'/aiffel/KoChatGPT/test'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",        #evaluation하는 빈도\n",
    "    logging_strategy=\"epoch\",           # epoch마다 로그 기록\n",
    "    learning_rate = 2e-5,               #learning_rate\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    logging_dir=\"./sft_logs\",\n",
    "    fp16 = True\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    \n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset, \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f326fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28779' max='28779' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28779/28779 1:26:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.541400</td>\n",
       "      <td>2.339253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.890400</td>\n",
       "      <td>2.300440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.468500</td>\n",
       "      <td>2.314573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('./modles/output_1_SFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40eeb91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.311244010925293,\n",
       " 'eval_runtime': 22.5163,\n",
       " 'eval_samples_per_second': 53.295,\n",
       " 'eval_steps_per_second': 53.295,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2f1c74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9593, Epoch: 1.0, Loss: 2.5414\n",
      "Step: 9593, Epoch: 1.0, Eval Loss: 2.3392531871795654\n",
      "Step: 19186, Epoch: 2.0, Loss: 1.8904\n",
      "Step: 19186, Epoch: 2.0, Eval Loss: 2.3004400730133057\n",
      "Step: 28779, Epoch: 3.0, Loss: 1.4685\n",
      "Step: 28779, Epoch: 3.0, Eval Loss: 2.314573287963867\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 후 로그 가져오기\n",
    "sft_logs = trainer.state.log_history\n",
    "\n",
    "display_train_graph(logs = sft_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f92cf0",
   "metadata": {},
   "source": [
    "**Generate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "613bf2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:   0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Generating: 100%|██████████| 100/100 [08:31<00:00,  5.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# 허깅페이스의 pipleline 클래스를 사용하여 generator 생성\n",
    "generator = pipeline('text-generation', model='./modles/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "test_count = 100 # 개수를 줄여보자\n",
    "\n",
    "# inputs\n",
    "inputs = []\n",
    "for idx, data in enumerate(test_dataset) : \n",
    "    if idx >= test_count :\n",
    "        break\n",
    "    input_ids = data['source_ids']\n",
    "    input_text = tokenizer.decode(input_ids , skip_special_tokens=True)\n",
    "    \n",
    "    inputs.append(input_text)\n",
    "       \n",
    "print(len(inputs))\n",
    "\n",
    "# references \n",
    "ref_labels = []\n",
    "for idx, data in enumerate(test_dataset) : \n",
    "    if idx >= test_count :\n",
    "        break\n",
    "    label_ids = data['labels']\n",
    "    label_text = tokenizer.decode([token for token in  label_ids  if token != -100], skip_special_tokens=True)\n",
    "    \n",
    "    ref_labels.append(label_text)\n",
    "    \n",
    "print(len(ref_labels))\n",
    "\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in inputs]\n",
    "\n",
    "#list_result = generator(list_prompt, **generation_args)   \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pred_results = []\n",
    "for input_text in tqdm(list_prompt, desc=\"Generating\"):\n",
    "    result = generator(input_text, **generation_args)\n",
    "    pred_results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "297f86d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '### Instruction(명령어):\\n### Instruction(명령어):\\n변명거리 생각해봐\\n\\n### Response(응답):\\n\\n### Response(응답):저는 인공지능 언어모델로써 변명을 할 수 없습니다. 하지만, 저는 항상 여러분의 질문에 답변해드릴 준비가 되어있습니다. 어떤 문제가 있으신가요? 제가 도와드릴 수 있는 것이 있다면 언제든지 말씀해주세요! 다시 한번'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(pred_results))\n",
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2edf4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "### Instruction(명령어):\n",
      "변명거리 생각해봐\n",
      "\n",
      "### Response(응답):\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 1. 시간이 부족해서 일이나 공부가 바쁘다는 것을 이유로 시간이 부족해서라는 변명을 할 수 있습니다. 2. 기분이 안 좋아서 정신적인 상태가 안 좋아서 일이나 공부에 집중을 못하겠다는 변명을 할 수 있습니다. 3. 장소를 잘못 선택했어서 공부나 작업을 할 때 조용한 장소나 적절한 공간을 선택하지 않아서 집중력이 떨어졌다는 변명을 할 수 있습니다. 4. 건강상의 이유로 건강문제로 인해 일이나 공부에 집중력이 떨어졌다는 변명을 할 수 있습니다. 5. 다른 이유로 인해 예상치 못한 일이나 사건으로 인해 일이나 공부에 집중력이 떨어졌다는 변명을 할 수 있습니다.\n",
      "[Gen   ] ### Instruction(명령어):\n",
      "### Instruction(명령어):\n",
      "변명거리 생각해봐\n",
      "\n",
      "### Response(응답):\n",
      "\n",
      "### Response(응답):저는 인공지능 언어모델로써 변명을 할 수 없습니다. 하지만, 저는 항상 여러분의 질문에 답변해드릴 준비가 되어있습니다. 어떤 문제가 있으신가요? 제가 도와드릴 수 있는 것이 있다면 언제든지 말씀해주세요! 다시 한번\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "### Instruction(명령어):\n",
      "방탄소년단은 한국 가수 최초로 몇 개의 앨범이 연속으로 빌보드 200차트에 올랐나?\n",
      "\n",
      "### Response(응답):\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] 방탄소년단은 5개의 앨범이 연속으로 빌보드 200차트에 올랐습니다. the most beautiful moment in life, part 2, the most beautiful moment in life young forever, wings, love yourself her, love yourself tear\n",
      "[Gen   ] ### Instruction(명령어):\n",
      "### Instruction(명령어):\n",
      "방탄소년단은 한국 가수 최초로 몇 개의 앨범이 연속으로 빌보드 200차트에 올랐나?\n",
      "\n",
      "### Response(응답):\n",
      "\n",
      "### Response(응답):방탄소년단의 한국 가수 최초로 6개의 앨범이 연속해서 빌보드 200 차트에 올랐습니다., token 125, today, please provide more context or information about the billboard of\n",
      "\n",
      "[Prompt] ### Instruction(명령어):\n",
      "### Instruction(명령어):\n",
      "boney m. 의 잠보 하쿠나 마타타를 부를 사람은?\n",
      "\n",
      "### Response(응답):\n",
      "\n",
      "### Response(응답):\n",
      "[Ref   ] boney m. 의 잠보 하쿠나 마타타를 부른 사람은 bobby farrell입니다.\n",
      "[Gen   ] ### Instruction(명령어):\n",
      "### Instruction(명령어):\n",
      "boney m. 의 잠보 하쿠나 마타타를 부를 사람은?\n",
      "\n",
      "### Response(응답):\n",
      "\n",
      "### Response(응답):저는 ai 어시스턴트이기 때문에, boney market 이 누구인지 알 수 없습니다. 추가적인 정보를 제공해주시면 더 정확한 답변을 드릴 수 있을 것입니다., token 125 다시 한번 강조해 주시면 감사하겠습니다\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for prompt, ref, result in zip(list_prompt, ref_labels, pred_results):\n",
    "    print()\n",
    "    print(\"[Prompt]\", prompt)\n",
    "    print(\"[Ref   ]\", ref)\n",
    "    print(\"[Gen   ]\", (result[0]['generated_text']))\n",
    "    cnt +=1\n",
    "    if cnt >= 3 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f66bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 인공지능 언어모델로써 변명을 할 수 없습니다. 하지만, 저는 항상 여러분의 질문에 답변해드릴 준비가 되어있습니다. 어떤 문제가 있으신가요? 제가 도와드릴 수 있는 것이 있다면 언제든지 말씀해주세요! 다시 한번\n"
     ]
    }
   ],
   "source": [
    "result = pred_results[0]\n",
    "response_raw = result[0][\"generated_text\"]\n",
    "response_clean = response_raw.split(\"### Response(응답):\")[-1].strip()\n",
    "print(response_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "690b06f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 시간이 부족해서 일이나 공부가 바쁘다는 것을 이유로 시간이 부족해서라는 변명을 할 수 있습니다. 2. 기분이 안 좋아서 정신적인 상태가 안 좋아서 일이나 공부에 집중을 못하겠다는 변명을 할 수 있습니다. 3. 장소를 잘못 선택했어서 공부나 작업을 할 때 조용한 장소나 적절한 공간을 선택하지 않아서 집중력이 떨어졌다는 변명을 할 수 있습니다. 4. 건강상의 이유로 건강문제로 인해 일이나 공부에 집중력이 떨어졌다는 변명을 할 수 있습니다. 5. 다른 이유로 인해 예상치 못한 일이나 사건으로 인해 일이나 공부에 집중력이 떨어졌다는 변명을 할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(ref_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bfbea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 ROUGE 점수\n",
      "ROUGE-1 F1: 0.1022\n",
      "ROUGE-2 F1: 0.0282\n",
      "ROUGE-L F1: 0.1011\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAF1CAYAAADiNYyJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfUklEQVR4nO3dfbRdd3kf+O8jS+YlJnGwHF4kG5PIU8ZJHNoISFi0IZnYsSi107wwpknmMnnx0MFW1yIzHXdCaAppk9CuZCrjWTGLplFoqUtJXxxijW1CnHcYy7w4sRlHF9dgmUB05RgwNkZCz/xxjuixuEb3yuf63Hv257PWWT5779/Z+znH2nd/z+/89t7V3QEAgKHZNOsCAABgFgRhAAAGSRAGAGCQBGEAAAZJEAYAYJAEYQAABkkQBhiYqvo/q+rtU1zfQ1X1jePnv15VPz/Fdf9qVf3stNYHMEkQBmaqqu6tqkfGYepT4yB1xgltXlpV76uqz1XVZ6rqt6rqgonlr6mqP3ycdX/vxPTOqnpPVf1VVT1YVXdV1T+tqq+fWM+XxrVMPp77OLVfVlUfrqrPVtXSuMbnT+/TWb2qurWqvjD+rD5bVbdX1dVV9ZTjbbr7n3X3T65wXSdt191ndPc9U6j9K/4/dvdru/vNT3TdAMsRhIH14O909xlJXpjkryf5R8cXVNV3Jrk5yX9J8twkz0/ykSR/dLwXciWq6qVJbk3yR0le0N1nJrkkydEk3zbR9E/GwW7y8cll1rcjyW8k+ekkXzeu69okX1ppTSuouarqVP5OX9ndz0jynHF9lye5sapqWrWN69s8zfUBPNkEYWDd6O5PJbkpo0B83FuS/EZ3/8vu/lx3P9Ddb0jy/iQ/t4rVvyXJv+7uX+juT4+394nu/sfdfesplPvCJP+1u3+nRz7X3b/Z3Z9Ikqo6bTwE4WPj3tnbq+qc8bKXVtVt497t28YhPeNlt457qf8oycNJvrGqXlBVt1TVA1V1d1W9aiUFdvfnx+/t0iTfmeRvj7fxc1X1b8bPn1pV/6aqDo97yW+rqmdV1T9N8jeTvHXcK/7WcfuuqtdV1YEkBybm7ZjY9NZxvZ+rqt+rqueN2503bvvlAH2817mq/vskv5rkO8fbe3C8/DFDLarqp6pqcfxZ3DDZWz9e92ur6sD4vVw77fAPzBdBGFg3qmp7kl1JFsfTT0/y0iT/YZnm70py0QrX+zUZBcHfnE6lSZIPJnlBVf1KVX33icM5krw+yauTvCLJ1yb58SQPV9Uzk/x2kj1Jzkryy0l+u6rOmnjtjyW5IskzkhxKckuSdyb5hox6d//vyaEhJzMO5/szCrYnWsioR/uccT2vTfJId/9Mkj/IqHf5jO6+cuI135/kJUker4YfSfLmJFuTfDjJv11BjR8db/t4j/yZJ7apqu9J8gtJXpVRb/fHk1x/QrNXJnlRkgvH7b7vZNsGhksQBtaD/1xVn0tyX5K/TPKPx/OfmdHfqb9Y5jV/kVHQWomvH6/nU8dnVNVbxr2Gn6+qN0y0/Y7x/OOPjy23wvGY2Jcn2ZZRKF+qx45v/skkb+juu8c9xh/p7sMZ9coe6O53dPfR7v53Sf6/JH9nYvW/3t13dvfRjIZv3Nvd/3rc/kMZBfofXuF7P+6TGX2eJzqSUQDe0d1f6u7bu/uzJ1nXL4x75h95nOW/3d2/392PJvmZjHp5z1llvcv5kSS/1t0fHK/7H43Xfd5Em1/s7gfH4f9389hfFwAeQxAG1oPvH49pfXmSF+S/Bdy/SnIso96/Ez0nydL4+dEkW5ZpsyWjoPcV6+nufzjudfxPSSbHur6/u8+ceHzT4xXd3e/v7ld199kZ9bb+rYyCXzLqYV0uRD83o57MSR/PKFAfd9/E8+cleclkOM8oED778ep6HNuSPLDM/HdkNBzl+qr65PgLwnKf5aT7Vrq8ux8ab3fZEw5X6TGf3Xjdh/PYz+5TE88fTnJiTz3AlwnCwLrR3b+X5NeT/Ivx9OeT/EmW7/18VZLfGT//RJJzJ8eDjodVfEOSj4/X84EkP7CGtd+W5D8m+ZbxrPuSLBeiP5lRuJ10bpL7J1c38fy+JL93Qjg/o7v//kprG/fGfntGQx1OrPtId/+T7r4go2Eor0zyPy1Tx2NedpJNfrn3d9xD/syM3vfnx7OfPtF2MtCfbL2P+ezGQ17OymM/O4AVE4SB9eb/SnJRVR2/ksPVSRaqandVPaOqvn588tR3Jvkn4zYfSPKFJFePT/76miS/mNG42OM9iP8wyY+PLyX2DcmXxySf0uXOqupl4xO3jq/rBRmdlPb+cZO3J3lzVZ0/vvrDheNxwDcm+e+q6u9V1eaq+h8zGmv7nsfZ1HvG7X+sqraMHy8an1x2shqfXlXfldEVN/7f8bZPbPPdVfWtVXVaks9m1IN+bLz400lWfGWOCa8Yfz6nZzRW+P3dfV93H8ootP5ojU4m/PE89svCp5NsH79uOf8uyf9cVS+s0eXg/lmSD3T3vadQI4AgDKwv47D0G0neOJ7+w4xOePqBjMYFfzyjS6y9rLsPjNs8mtHY25cnOZjknox+Rn9Vd/fEer4no+ELfz4eYvD/ZHRJtWsmSjh+1YLJx4uWKfXBjILvn1bVQ+N1/aeMrk6RjE6Ce1dGl377bJJ/leRp43HCr8zosmaHMwror+zupSyjuz+X5OKMTpL7ZEY//f9Skqcs137sreMx15/O6IvFbya5pLuPLdP22UnePa7xo0l+L6PhEknyL5P8UI2uu7znq2zvRO/MaJz3Axn1RP/oxLKfSvK/Z/TevznJH08se1+SO5N8qqq+4vPo7vcm+dnx+/mLjEL05auoC+AxanyMAACAQdEjDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCBtPnmTtbF169Y+77zzZrV5AAAG4vbbb18a3wX0MWYWhM8777zs379/VpsHAGAgqurEW9snMTQCAICBEoQBABgkQRgAgEEShAEAGCRBGACAQRKEAQAYJEEYAIBBEoQBABgkQZhVW1paylVXXZXDhw/PuhQAWHOOe/NLEGbV9u7dmzvuuCN79+6ddSkAsOYc9+aXIMyqLC0tZd++fenu7Nu3z7djAOaa4958E4RZlb1796a7kyTHjh3z7RiAuea4N98EYVbllltuyZEjR5IkR44cyc033zzjigBg7TjuzTdBmFW56KKLsmXLliTJli1bcvHFF8+4IgBYO457800QZlUWFhZSVUmSTZs2ZWFhYcYVAcDacdybb4Iwq7J169bs2rUrVZVdu3blrLPOmnVJALBmHPfm24qCcFVdUlV3V9ViVV29zPLXVNWhqvrw+PGT0y+V9WJhYSEXXnihb8UADILj3vyq42dCPm6DqtOS/HmSi5IcTHJbkld3910TbV6TZGd3X7nSDe/cubP3799/KjUDAMCKVdXt3b3zxPkr6RF+cZLF7r6nu7+Y5Pokl027QAAAeDKtJAhvS3LfxPTB8bwT/WBV3VFV766qc5ZbUVVdUVX7q2r/oUOHTqFcAACYjmmdLPdbSc7r7guT3JJk2atNd/fbuntnd+88++yzp7RpAABYvZUE4fuTTPbwbh/P+7LuPtzdj44n357k26dTHgAArI2VBOHbkpxfVc+vqtOTXJ7khskGVfWciclLk3x0eiUCAMD0bT5Zg+4+WlVXJrkpyWlJfq2776yqNyXZ3903JNldVZcmOZrkgSSvWcOaAQDgCTvp5dPWisunAQDwZHgil08DAIC5IwgDADBIgjAAAIMkCAMAMEiCMAAAgyQIAwAwSIIwAACDJAgDADBIgjAAAIMkCAMAMEiCMAAAgyQIAwAwSIIwAACDJAgDADBIgjAAAIMkCAMAMEiCMAAAgyQIAwAwSIIwAACDJAgDADBIgjAAAIMkCAMAMEiCMAAAgyQIAwAwSIIwAACDJAgDADBIgjAAAIMkCAMAMEiCMAAAgyQIAwAwSIIwAACDJAgDADBIgjAAAIMkCAMAMEiCMAAAgyQIAwAwSIIwAACDJAgDADBIgjAAAIMkCAMAMEiCMAAAgyQIAwAwSIIwAACDJAgDADBIgjAAAIMkCAMAMEiCMAAAgyQIAwAwSIIwAACDtKIgXFWXVNXdVbVYVVd/lXY/WFVdVTunVyIAAEzfSYNwVZ2W5Noku5JckOTVVXXBMu2ekeQfJPnAtIsEAIBpW0mP8IuTLHb3Pd39xSTXJ7lsmXZvTvJLSb4wxfoAAGBNrCQIb0ty38T0wfG8L6uqv5HknO7+7a+2oqq6oqr2V9X+Q4cOrbpYAACYlid8slxVbUryy0l++mRtu/tt3b2zu3eeffbZT3TTAABwylYShO9Pcs7E9PbxvOOekeRbktxaVfcm+Y4kNzhhDgCA9WwlQfi2JOdX1fOr6vQklye54fjC7v5Md2/t7vO6+7wk709yaXfvX5OKAQBgCk4ahLv7aJIrk9yU5KNJ3tXdd1bVm6rq0rUuEAAA1sLmlTTq7huT3HjCvDc+TtuXP/GyAABgbbmzHAAAgyQIs2pLS0u56qqrcvjw4VmXAgBrznFvfgnCrNrevXtzxx13ZO/evbMuBQDWnOPe/BKEWZWlpaXs27cv3Z19+/b5dgzAXHPcm2+CMKuyd+/edHeS5NixY74dAzDXHPfmmyDMqtxyyy05cuRIkuTIkSO5+eabZ1wRAKwdx735JgizKhdddFG2bNmSJNmyZUsuvvjiGVcEAGvHcW++CcKsysLCQqoqSbJp06YsLCzMuCIAWDuOe/NNEGZVtm7dml27dqWqsmvXrpx11lmzLgkA1ozj3nxb0Z3lYNLCwkLuvfde34oBGATHvflVx8+EfLLt3Lmz9+/fP5NtAwAwHFV1e3fvPHG+oREAG4S7WwFMlyAMsEG4uxXAdAnCABuAu1sBTJ8gDLABuLsVwPQJwgAbgLtbAUyfIAywAbi7FcD0CcIAG4C7WwFMnyAMsAG4uxXA9LmzHMAG4e5WANMlCANsEFu3bs0111wz6zIA5oahEQAADJIgDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAMkiAMAMAgrSgIV9UlVXV3VS1W1dXLLH9tVf1pVX24qv6wqi6YfqkAADA9Jw3CVXVakmuT7EpyQZJXLxN039nd39rdL0zyliS/PO1CAQBgmlbSI/ziJIvdfU93fzHJ9Ukum2zQ3Z+dmPyaJD29EgEAYPo2r6DNtiT3TUwfTPKSExtV1euSvD7J6Um+Z7kVVdUVSa5IknPPPXe1tQIAwNRM7WS57r62u78pyf+R5A2P0+Zt3b2zu3eeffbZ09o0AACs2kqC8P1JzpmY3j6e93iuT/L9T6AmAABYcysJwrclOb+qnl9Vpye5PMkNkw2q6vyJyb+d5MD0SgQAgOk7aRDu7qNJrkxyU5KPJnlXd99ZVW+qqkvHza6sqjur6sMZjRNeWKuCAYZqaWkpV111VQ4fPjzrUgDmwkpOlkt335jkxhPmvXHi+T+Ycl0AnGDv3r254447snfv3rz+9a+fdTkAG547ywFsAEtLS9m3b1+6O/v27dMrDDAFgjDABrB37950jy7RfuzYsezdu3fGFQFsfIIwwAZwyy235MiRI0mSI0eO5Oabb55xRQAbnyAMsAFcdNFF2bJlS5Jky5Ytufjii2dcEcDGJwgDbAALCwupqiTJpk2bsrDg4jwAT5QgDLABbN26Nbt27UpVZdeuXTnrrLNmXRLAhreiy6cBMHsLCwu599579QYDTIkgDLBBbN26Nddcc82sywCYG4ZGAAAwSIIwAACDJAgDADBIgjAAAIMkCAMAMEiCMAAAgyQIAwAwSIIwAACD5IYaM7Znz54sLi7OuoxVOXjwYJJk+/btM65k5Xbs2JHdu3fPugyAwXPce/I49p2cIMyqPfLII7MuAQCeNI5786u6eyYb3rlzZ+/fv38m2+aJOf7tcs+ePTOuBADWnuPexldVt3f3zhPnGyMMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAM0oqCcFVdUlV3V9ViVV29zPLXV9VdVXVHVf1OVT1v+qUCAMD0nDQIV9VpSa5NsivJBUleXVUXnNDsQ0l2dveFSd6d5C3TLhQAAKZpJT3CL06y2N33dPcXk1yf5LLJBt39u9398Hjy/Um2T7dMAACYrpUE4W1J7puYPjie93h+Ism+5RZU1RVVtb+q9h86dGjlVQIAwJRN9WS5qvrRJDuT/PPllnf327p7Z3fvPPvss6e5aQAAWJXNK2hzf5JzJqa3j+c9RlV9b5KfSfJd3f3odMoDAIC1sZIe4duSnF9Vz6+q05NcnuSGyQZV9deTXJfk0u7+y+mXCQAA03XSINzdR5NcmeSmJB9N8q7uvrOq3lRVl46b/fMkZyT5D1X14aq64XFWBwAA68JKhkaku29McuMJ89448fx7p1wXAACsKXeWAwBgkARhAAAGSRAGAGCQBGEAAAZJEAYAYJAEYQAABkkQBgBgkARhAAAGSRAGAGCQBGEAAAZJEAYAYJAEYQAABkkQBgBgkARhAAAGSRAGAGCQBGEAAAZJEAYAYJA2z7qAadqzZ08WFxdnXcbcO3DgQJJk9+7dM65kvu3YscNnDABraK6C8OLiYj70p3fl2NOfOetS5lp9sZMkt3/sUzOuZH5teviBWZcAAHNvroJwkhx7+jPzhQteOesy4Al56l3vmXUJADD35i4IA8CQGBa49gwJfHLMYkigIAwAG9ji4mI+dOeHkjNnXckcOzb6z4fu/9Bs65hnD85ms4IwAGx0ZybHXn5s1lXAKdt062wuZObyaQAADJIgDADAIAnCAAAMkiAMAMAgCcIAAAySIAwAwCAJwgAADJIgDADAIAnCAAAMkiAMAMAgCcIAG8TS0lKuuuqqHD58eNalAMwFQRhgg7juuuvykY98JNddd92sSwGYC4IwwAawtLSUW265JUly88036xUGmAJBGGADuO6663Ls2LEkybFjx/QKA0yBIAywAbz3ve99zPTx3mEATp0gDADAIAnCABvAc5/73K86DcDqCcIAG8DS0tJXnQZg9QRhgA3g4osvTlUlSaoq3/d93zfjigA2PkEYYANYWFjI5s2bkySbN2/OwsLCjCsC2PgEYYANYOvWrdm2bVuSZNu2bTnrrLNmXBHAxicIA2wAS0tLuf/++5Mk999/vxtqAEyBIAywAezduzdHjx5Nkhw9ejR79+6dcUUAG58gDLAB3HzzzenuJEl356abbppxRQAbnyAMsAE861nP+qrTAKyeIAywAXz605/+qtMArN6KgnBVXVJVd1fVYlVdvczyv1VVH6yqo1X1Q9MvE2DYXEcYYPpOGoSr6rQk1ybZleSCJK+uqgtOaPaJJK9J8s5pFwjAY68jvGXLFtcRBpiClfQIvzjJYnff091fTHJ9kssmG3T3vd19R5Jja1AjwOBt3bo1r3jFK1JVecUrXuE6wgBTsJIgvC3JfRPTB8fzVq2qrqiq/VW1/9ChQ6eyCoDBWlhYyIUXXqg3GGBKntST5br7bd29s7t3nn322U/mpgE2vK1bt+aaa67RGwwwJSsJwvcnOWdievt4HgAAbFgrCcK3JTm/qp5fVacnuTzJDWtbFgAArK2TBuHuPprkyiQ3Jfloknd1951V9aaqujRJqupFVXUwyQ8nua6q7lzLogEA4InavJJG3X1jkhtPmPfGiee3ZTRkAgAANoQVBWGAebNnz54sLi7OuoxVOXjwYJJk+/aN1e+wY8eO7N69e9ZlAHyFuQrCBw8ezKaHP5On3vWeWZcCT8imhw/n4MGjsy6DdeaRRx6ZdQkAc2WugjDASm3EHsrjNe/Zs2fGlQDMh7kKwtu3b8+nH92cL1zwylmXAk/IU+96T7Zvf/asywA2gIMHDyafSTbd+qTeGgCm68HkYB980jdrrwEAYJDmqkcYAIZm+/btOVSHcuzlx2ZdCpyyTbduyvZtT/6JwHqEAQAYJEEYAIBBEoQBABgkQRgAgEEShAEAGCRBGACAQRKEAQAYJEEYAIBBEoQBABgkQRgAgEEShAEAGCRBGACAQRKEAQAYJEEYAIBBEoQBABgkQRgAgEEShAEAGCRBGACAQRKEAQAYJEEYAIBBEoQBABgkQRgAgEEShAEAGCRBGACAQdo86wKA+bBnz54sLi7Ouoy5duDAgSTJ7t27Z1zJfNuxY4fPGAZi7oLwpocfyFPves+sy5hr9YXPJkn6qV8740rm16aHH0jy7FmXsSqLi4v58z/7YM4940uzLmVunX5k9CPeF+69bcaVzK9PPHTarEs4NQ8mm271I++aeWj83zNmWsV8ezDJtid/s3MVhHfs2DHrEgbhwIHPJUnO/6aNFdQ2lmdvyH/P557xpbxh50Mnbwjr1M/v33hJZyP+rdhojv8ac/6282dcyRzbNpt/y3MVhP2U9eQ4/jnv2bNnxpUA4Ni39hz35pffUQAAGCRBGACAQRKEAQAYJEEYAIBBEoQBABgkQRgAgEEShAEAGCRBGACAQRKEAQAYJEEYAIBBEoQBABgkQRgAgEEShAEAGCRBGACAQRKEAQAYpBUF4aq6pKrurqrFqrp6meVPqap/P17+gao6b+qVAgDAFJ00CFfVaUmuTbIryQVJXl1VF5zQ7CeS/FV370jyK0l+adqFAgDANG1eQZsXJ1ns7nuSpKquT3JZkrsm2lyW5OfGz9+d5K1VVd3dU6x1Lu3ZsyeLi4uzLmNVDhw4kCTZvXv3jCtZuR07dmyoejeigwcP5oEHN+enfvfrZl3Kihw5VjnmL9STYlMlWzZtjA/70S9Vnnnw4KzLmGuOe08ex76TW0kQ3pbkvonpg0le8nhtuvtoVX0myVlJliYbVdUVSa5IknPPPfcUS2bWnva0p826BNahM888M4888sisy1i5Rx9Njh2bdRXDsGlTNj3lKbOuYkWeltG/ZZjkuDe/6mSdtlX1Q0ku6e6fHE//WJKXdPeVE23+bNzm4Hj6Y+M2S8utM0l27tzZ+/fvn8JbAACAx1dVt3f3zhPnr+RkufuTnDMxvX08b9k2VbU5ydclOXxqpQIAwNpbSRC+Lcn5VfX8qjo9yeVJbjihzQ1JFsbPfyjJ+4wPBgBgPTvpGOHxmN8rk9yU5LQkv9bdd1bVm5Ls7+4bkvyrJO+oqsUkD2QUlgEAYN1aycly6e4bk9x4wrw3Tjz/QpIfnm5pAACwdtxZDgCAQRKEAQAYJEEYAIBBEoQBABgkQRgAgEEShAEAGCRBGACAQRKEAQAYJEEYAIBBqu6ezYarDiX5+Ew2zjRsTbI06yJggOx7MBv2vY3ted199okzZxaE2diqan9375x1HTA09j2YDfvefDI0AgCAQRKEAQAYJEGYU/W2WRcAA2Xfg9mw780hY4QBABgkPcIAAAySIDznqupLVfXhqvqzqvqtqjpzYtk3V9X7quruqjpQVT9bVTVe9nNV9b+dsK57q2rr+PmzquqdVXVPVd1eVX9SVX93vOzlVfWZ8XaPP753mdpeMH7doyduCza6db7v/UhV3VFVf1pVf1xV37amHwY8ydb5/veaqnrrmn4ArJggPP8e6e4Xdve3JHkgyeuSpKqeluSGJL/Y3X8tybcleWmS//VkKxz/wfjPSX6/u7+xu789yeVJtk80+4Pxdo8/3rvMqh5IsjvJvzj1twfr1nre9/5rku/q7m9N8uYY+8j8Wc/7H+uIIDwsf5Jk2/j530vyR919c5J098NJrkxy9QrW8z1Jvtjdv3p8Rnd/vLuvWU0x3f2X3X1bkiOreR1sQOtt3/vj7v6r8eT789gDOcybdbX/sb4IwgNRVacl+R8y+iacJN+c5PbJNt39sSRnVNXXnmR135zkgydp8zdP+Hnom06lbtjoNsC+9xNJ9p2kDWxIG2D/Y8Y2z7oA1tzTqurDGX0b/miSW1b4use7nMhXzK+qa5O8LKNvyi8az/6D7n7lKmuFebLu972q+u6MgvDLVlgbbBTrfv9jfdAjPP8e6e4XJnleksp4nFSSu5J8+2TDqvrGJA9192eTHE7y9Ses6xlJHkxyZ5K/cXxmd78uo2/cX3EP7xPW/7qJb8nPPdU3BBvEut73qurCJG9Pcll3Hz6VNwjr2Lre/1g/BOGBGI+D2p3kp6tqc5J/m+Rlx89oHZ9AsCfJW8Yv+f0kl1bVM8bLfyDJR7r7S0nel+SpVfX3Jzbx9BXUcO3ECQSfnNZ7g/VsPe57VXVukv+Y5Me6+8+n805h/VmP+9+03hvT4YYac66qHuruMyamfyvJu7r7HVX1rUmuSfKcJKcleUeSN/X4H0VV/S8ZnUnbSf4yyWu7+57xsuck+ZUkL0lyKMnnk/xqd//7qnp5kv+S0Znpx/18d7/7hNqenWR/kq9NcizJQ0kuGH8rhw1tne97b0/yg0k+Pp51tLt3TvHtw0yt8/3vNUnemlEv83Hf0d0Hp/LmWRVBGACAQTI0AgCAQRKEAQAYJEEYAIBBEoQBABgkQRgAgEEShAEAGCRBGACAQRKEAQAYpP8f+ZzwgisTmYQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pred_texts = [\n",
    "    r[0][\"generated_text\"].split(\"### Response(응답):\")[-1].strip()\n",
    "    for r in pred_results\n",
    "    ]\n",
    "    \n",
    "compute_rouge(ref_labels, pred_texts )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b5eab",
   "metadata": {},
   "source": [
    "# < 회고 >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0caaec0",
   "metadata": {},
   "source": [
    "### 테스트 목표 : 루브릭 1번\n",
    "1. KoGTP와 SFP의 훈련 결과를 loss, perplexity를 비교\n",
    "2. test set에 대한 generate의 결과를 Rogue로 비교\n",
    "3. generate의 결과 중 몇개를 출력하여 정성적으로 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c278aa9",
   "metadata": {},
   "source": [
    "### 어려운점 및 시험 기록\n",
    "1. CUDA OOM 문제로 \n",
    "   - tokenizer의 max_length를 512 -> 384로 변경 \n",
    "   - batch size 1로 변경\n",
    "   - prediction_loss_only=True이면 loss 정보만 출력되어서 False로 했다가, 다시 True로 바꿔봄\n",
    "       + perplexity는 출력되지 않음\n",
    "2. generate \n",
    "   - generate는 test_dataset 1200개중 100개만 사용\n",
    "3. 시간 문제로\n",
    "   - KoGPT는 epoch 1만 돌렸는데, SFT 3 epoch(1시간40분 소요) 결과와 비교하였음\n",
    "   <- 시간이 되면 KoGPT도 3 epoch 수행할 것!\n",
    "   - trainer.evaluate는 하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60f683",
   "metadata": {},
   "source": [
    "### test summary \n",
    "\n",
    "✅ ROUGE 점수\n",
    "\n",
    "| Metric  | KoGPT F1 Score | SFT F1 Score |\n",
    "| ------- | -------- |-------- |\n",
    "| ROUGE-1 | 0.1404   |  0.1022 |\n",
    "| ROUGE-2 | 0.0647   |  0.0282|\n",
    "| ROUGE-L | 0.1394   |  0.1011|\n",
    "\n",
    "✅ Loss 비교 \n",
    "\n",
    "| Epoch | KoGPT Training Loss | KoGPT Validation Loss | SFT Training Loss | SFT Validation Loss |\n",
    "| ----- | ------------- | --------------- |------------- | --------------- |\n",
    "| 1     | 2.556800      |2.297744         |  2.5414      | 2.3393          |\n",
    "| 2     |               |                 |1.8904        | 2.3004          |\n",
    "| 3     |               |                 |1.4685        | 2.3146          |\n",
    "\n",
    "✅ 생성문장 비교 \n",
    "- prompt : 변명거리를 생각해 봐\n",
    "- KoGPT : 제가 ai 챗봇이기 때문에, 어떤 문제가 있는지 자세히 설명해주시면 답변을 드릴 수 있을 것 같습니다.\n",
    "- SFT : 저는 인공지능 언어모델로써 변명을 할 수 없습니다. 하지만, 저는 항상 여러분의 질문에 답변해드릴 준비가 되어있습니다. 어떤 문제가 있으신가요? 제가 도와드릴 수 있는 것이 있다면 언제든지 말씀해주세요! 다시 한번\n",
    "\n",
    "- prompt : boney m. 의 잠보 하쿠나 마타타를 부를 사람은?\n",
    "- KoGPT : 저는 ai 어시스턴트이기 때문에, 이 질문에 대한 답변을 제공할 수 없습니다.\n",
    "- SFT : 저는 ai 어시스턴트이기 때문에, boney market 이 누구인지 알 수 없습니다. 추가적인 정보를 제공해주시면 더 정확한 답변을 드릴 수 있을 것입니다., token 125 다시 한번 강조해 주시면 감사하겠습니다\n",
    "\n",
    "✅ 종합 평가\n",
    "1. Rouge 점수는 낮지만, SFT가 더 자연스러운 문장을 구사한다.\n",
    "2. training loss는 둘다 비슷하다. training loss는 줄어들지만, validation loss는 줄어들지 않는다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
